{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2483a0-2147-488f-8276-5d7917c413dc",
   "metadata": {
    "id": "ad2483a0-2147-488f-8276-5d7917c413dc"
   },
   "source": [
    "## Agentic rag using vertex ai\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/agent/agentic_rag_using_vertex_ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5b1b8-8314-4e9b-88a1-6b0dee8ed2cb",
   "metadata": {
    "id": "7ba5b1b8-8314-4e9b-88a1-6b0dee8ed2cb"
   },
   "source": [
    "### Build Agentic RAG with Llamaindex for Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb73543-5f34-43c5-a0e6-4906daa89bbe",
   "metadata": {
    "id": "fcb73543-5f34-43c5-a0e6-4906daa89bbe"
   },
   "source": [
    "#### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad084c0-a3b5-4129-acb9-1de7d8bee637",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6243,
     "status": "ok",
     "timestamp": 1730974673042,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "9ad084c0-a3b5-4129-acb9-1de7d8bee637",
    "outputId": "b79889fb-a8f0-4e6c-9dd2-4d094e639dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (1.71.1)\n",
      "Requirement already satisfied: llama-index-vector-stores-vertexaivectorsearch in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: llama-index in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (0.11.21)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.22-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: llama_index-llms-vertex in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (0.3.7)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (5.28.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.13.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.9.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-vector-stores-vertexaivectorsearch) (0.11.21)\n",
      "Requirement already satisfied: llama-index-embeddings-vertex<0.3.0,>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-vector-stores-vertexaivectorsearch) (0.2.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.3.4)\n",
      "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.3.1)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-vector-stores-vertexaivectorsearch)\n",
      "  Downloading llama_index_core-0.11.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.5)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.9.48.post3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.2.2)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: pyarrow<16.0.0,>=15.0.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama_index-llms-vertex) (15.0.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.53.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (2024.10.0)\n",
      "Requirement already satisfied: httpx in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (3.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (11.0.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.0.11 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.1.4)\n",
      "Requirement already satisfied: pandas in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.13)\n",
      "Requirement already satisfied: click in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.0.6)\n",
      "Requirement already satisfied: idna in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (3.23.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/tubakaraca/py312_jupyter_env/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-vertexaivectorsearch) (0.2.0)\n",
      "Downloading llama_index-0.11.22-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_core-0.11.22-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llama-index-core, llama-index\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.21\n",
      "    Uninstalling llama-index-core-0.11.21:\n",
      "      Successfully uninstalled llama-index-core-0.11.21\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.11.21\n",
      "    Uninstalling llama-index-0.11.21:\n",
      "      Successfully uninstalled llama-index-0.11.21\n",
      "Successfully installed llama-index-0.11.22 llama-index-core-0.11.22\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform llama-index-vector-stores-vertexaivectorsearch llama-index llama_index-llms-vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6b3a3-b001-4538-aa0d-a543a670fc5d",
   "metadata": {
    "id": "cfe6b3a3-b001-4538-aa0d-a543a670fc5d"
   },
   "source": [
    "#### Restart current runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eZXDyiD7MMC2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1730974704973,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "eZXDyiD7MMC2",
    "outputId": "9a6a970d-8221-4eae-89bd-b7f907b05af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colab only\n",
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z2wSMFUg9UWI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1730938228644,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "z2wSMFUg9UWI",
    "outputId": "30099ebd-d82b-4591-b2a1-9ea21ae61984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
     ]
    }
   ],
   "source": [
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hEgBD1ppMXoy",
   "metadata": {
    "id": "hEgBD1ppMXoy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=KMdKMI2AmeJgSB9LMb6p7IOjZ6ndBb&access_type=offline&code_challenge=JCEUtWnOAla3oJHaE4c5fYRrrJ6otqbO9wcoZ0LE-kc&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [tubakadriye17@gmail.com].\n",
      "Your current project is [gender-equity-navigator].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "\n",
      "\n",
      "Updates are available for some Google Cloud CLI components.  To install them,\n",
      "please run:\n",
      "  $ gcloud components update\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're using JupyterLab instance, uncomment and run the below code.\n",
    "!gcloud auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1pKvY0tU9oUw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "executionInfo": {
     "elapsed": 16385,
     "status": "ok",
     "timestamp": 1730938328623,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "1pKvY0tU9oUw",
    "outputId": "0d797d5b-2734-4edd-f04d-dbef3dea92f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c829e63f-9be7-43a4-90e1-33460a6da4f6\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c829e63f-9be7-43a4-90e1-33460a6da4f6\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving gender-equity-navigator-cb89eefec226.json to gender-equity-navigator-cb89eefec226.json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aDWKc3zl9w0-",
   "metadata": {
    "id": "aDWKc3zl9w0-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from google.auth.transport.requests import Request\n",
    "from google.colab import auth\n",
    "\n",
    "# Path to your service account key file (replace 'your-service-account-file.json' with the uploaded file name)\n",
    "service_account_key_path = 'gender-equity-navigator-cb89eefec226.json'\n",
    "\n",
    "# Load the credentials from the service account file\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    service_account_key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "\n",
    "# Set the environment variable for authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed512d-4f99-4797-8d7e-9910810dd99d",
   "metadata": {
    "id": "3fed512d-4f99-4797-8d7e-9910810dd99d"
   },
   "source": [
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add11b07-55e8-48a2-a5d7-90cf68514649",
   "metadata": {
    "id": "add11b07-55e8-48a2-a5d7-90cf68514649"
   },
   "source": [
    "### Define Google Cloud project information and initialize Vertex AI\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c312452a-97d7-4886-a128-9a0e6f0ed2a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1730940791335,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "c312452a-97d7-4886-a128-9a0e6f0ed2a9"
   },
   "outputs": [],
   "source": [
    "API_KEY= \"AIzaSyDeIRtW4T5liuHcz-i_Gj4lk7_k28iPEhU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9cd078-06cd-4266-a896-d14133d7bc6d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1730940792463,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "5e9cd078-06cd-4266-a896-d14133d7bc6d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GOOGLE_API_KEY = API_KEY  # add your GOOGLE API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc31ab9-ce76-47f8-89fb-cd5e69fb0d31",
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1730940793741,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "1bc31ab9-ce76-47f8-89fb-cd5e69fb0d31"
   },
   "outputs": [],
   "source": [
    "# Project and Storage Constants\n",
    "PROJECT_ID = \"gender-equity-navigator\"\n",
    "REGION = \"europe-west1\"\n",
    "GCS_BUCKET_NAME = \"gender-equity-research-docs\"\n",
    "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43033aef-313e-470e-9c59-6b522ca928fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1730940794675,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "43033aef-313e-470e-9c59-6b522ca928fe"
   },
   "outputs": [],
   "source": [
    "# The number of dimensions for the textembedding-gecko@003 is 768\n",
    "# If other embedder is used, the dimensions would probably need to change.\n",
    "VS_DIMENSIONS = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ab869b-c4cb-4a3b-92eb-d56ba6f09afe",
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1730940795755,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "64ab869b-c4cb-4a3b-92eb-d56ba6f09afe"
   },
   "outputs": [],
   "source": [
    "# Vertex AI Vector Search Index configuration\n",
    "# parameter description here\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n",
    "VS_INDEX_NAME = \"gender_equity_vector_search_index\"  # @param {type:\"string\"}\n",
    "VS_INDEX_ENDPOINT_NAME = \"gender_equity_vector_search_endpoint\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec43618-e74e-4d97-ba5f-5f8b7ce6378b",
   "metadata": {
    "executionInfo": {
     "elapsed": 2753,
     "status": "ok",
     "timestamp": 1730940799668,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "4ec43618-e74e-4d97-ba5f-5f8b7ce6378b"
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e9285c68-cfe1-49db-9cca-b52a4d1a2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07203b10-b325-4ddf-8746-074f90e3747f",
   "metadata": {
    "id": "07203b10-b325-4ddf-8746-074f90e3747f"
   },
   "source": [
    "## Set Up Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9cd901-8809-4fa7-9a20-627627fd50c1",
   "metadata": {
    "id": "3d9cd901-8809-4fa7-9a20-627627fd50c1"
   },
   "source": [
    "## Create a new Vertex AI Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7850f97-7015-46ba-aba9-eaf857fb6eb3",
   "metadata": {
    "id": "a7850f97-7015-46ba-aba9-eaf857fb6eb3"
   },
   "source": [
    "**Create an empty index**\n",
    "\n",
    "A streaming index is when you want index data to be updated as new data is added to your datastore, for instance, if you have a bookstore and want to show new inventory online as soon as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d74d23-0f7e-4510-ba87-8927f42a3c7e",
   "metadata": {
    "id": "86d74d23-0f7e-4510-ba87-8927f42a3c7e",
    "outputId": "0760283c-ffcd-4ee2-f12b-930b8b2bea7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector Search index gender_equity_vector_search_index ...\n",
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/135008850867/locations/europe-west1/indexes/5918794237620518912/operations/2890462412673122304\n",
      "MatchingEngineIndex created. Resource name: projects/135008850867/locations/europe-west1/indexes/5918794237620518912\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/135008850867/locations/europe-west1/indexes/5918794237620518912')\n",
      "Vector Search index gender_equity_vector_search_index created with resource name projects/135008850867/locations/europe-west1/indexes/5918794237620518912\n"
     ]
    }
   ],
   "source": [
    "VS_INDEX_NAME = \"gender_equity_vector_search_index\"  # @param {type:\"string\"}\n",
    "VS_INDEX_ENDPOINT_NAME = \"gender_equity_vector_search_endpoint\"  # @param {type:\"string\"}\n",
    "VS_DIMENSIONS = 768\n",
    "\n",
    "# check if index exists\n",
    "index_names = [\n",
    "    index.resource_name\n",
    "    for index in aiplatform.MatchingEngineIndex.list(\n",
    "        filter=f\"display_name={VS_INDEX_NAME}\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "if len(index_names) == 0:\n",
    "    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
    "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=VS_INDEX_NAME,\n",
    "        dimensions=VS_DIMENSIONS,\n",
    "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "        approximate_neighbors_count=150,\n",
    "        shard_size=\"SHARD_SIZE_SMALL\",\n",
    "        index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c8ef8-6943-46ff-8379-1de7bed8757c",
   "metadata": {
    "id": "e34c8ef8-6943-46ff-8379-1de7bed8757c"
   },
   "source": [
    "**Create an endpoint**\n",
    "\n",
    "To use the index, you need to create an index endpoint. It works as a server instance accepting query requests for your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019ca05-2a40-47b1-9dad-55e64d4ff37d",
   "metadata": {
    "id": "4019ca05-2a40-47b1-9dad-55e64d4ff37d",
    "outputId": "ae9cf374-d189-44a9-9069-b2020984f79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector Search index endpoint gender_equity_vector_search_endpoint ...\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416/operations/4268563898648494080\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416')\n",
      "Vector Search index endpoint gender_equity_vector_search_endpoint created with resource name projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n"
     ]
    }
   ],
   "source": [
    "endpoint_names = [\n",
    "    endpoint.resource_name\n",
    "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
    "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n",
    "    )\n",
    "]\n",
    "\n",
    "if len(endpoint_names) == 0:\n",
    "    print(\n",
    "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
    "    )\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        index_endpoint_name=endpoint_names[0]\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d96adc-bd1e-41d8-97d0-24f7ba141f17",
   "metadata": {
    "id": "72d96adc-bd1e-41d8-97d0-24f7ba141f17"
   },
   "source": [
    "**Deploy index to endpoint**\n",
    "\n",
    "With the index endpoint, deploy the index by specifying a unique deployed index ID.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40aa12-d17c-431a-93ec-7c0c35468263",
   "metadata": {
    "id": "7b40aa12-d17c-431a-93ec-7c0c35468263",
    "outputId": "cb9d39cf-7c81-404a-ee09-a30572142c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Vector Search index gender_equity_vector_search_index at endpoint gender_equity_vector_search_endpoint ...\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416/operations/6786076090348601344\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "Vector Search index gender_equity_vector_search_index is deployed at endpoint gender_equity_vector_search_endpoint\n"
     ]
    }
   ],
   "source": [
    "# check if endpoint exists\n",
    "# it takes about 30 mins to finish\n",
    "index_endpoints = [\n",
    "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
    "    for deployed_index in vs_index.deployed_indexes\n",
    "]\n",
    "\n",
    "if len(index_endpoints) == 0:\n",
    "    print(\n",
    "        f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
    "    )\n",
    "    vs_deployed_index = vs_endpoint.deploy_index(\n",
    "        index=vs_index,\n",
    "        deployed_index_id=VS_INDEX_NAME,\n",
    "        display_name=VS_INDEX_NAME,\n",
    "        machine_type=\"e2-standard-16\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1,\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        index_endpoint_name=index_endpoints[0][0]\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491ef40-a3d3-4e29-9b9c-95236fd4b01c",
   "metadata": {
    "id": "3491ef40-a3d3-4e29-9b9c-95236fd4b01c"
   },
   "source": [
    "### Use an existing Vertex AI Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc95305f-0269-4d77-8d09-a167f598dbd8",
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1730940810293,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "bc95305f-0269-4d77-8d09-a167f598dbd8"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8db88c72-1ecc-495b-860b-2faf0d268e97",
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1730940811436,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "8db88c72-1ecc-495b-860b-2faf0d268e97"
   },
   "outputs": [],
   "source": [
    "\n",
    "vs_index = aiplatform.MatchingEngineIndex(index_name=\"5918794237620518912\")\n",
    "\n",
    "vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name=\"6059426172859580416\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f533f-5424-4039-a2a8-5f6cc484114c",
   "metadata": {
    "id": "103f533f-5424-4039-a2a8-5f6cc484114c"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fea0b65-c1f7-4d41-abd0-63ef3615cdda",
   "metadata": {
    "executionInfo": {
     "elapsed": 4051,
     "status": "ok",
     "timestamp": 1730940819255,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "0fea0b65-c1f7-4d41-abd0-63ef3615cdda"
   },
   "outputs": [],
   "source": [
    "# import modules needed\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilters,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.llms.vertex import Vertex\n",
    "from llama_index.embeddings.vertex import VertexTextEmbedding\n",
    "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore\n",
    "\n",
    "from typing import List, Optional\n",
    "from llama_index.core.vector_stores import FilterCondition\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "from pathlib import Path\n",
    "\n",
    "from llama_index.core.agent import FunctionCallingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd190c03-7c8b-4707-8482-feae111225cd",
   "metadata": {
    "id": "bd190c03-7c8b-4707-8482-feae111225cd"
   },
   "outputs": [],
   "source": [
    "#!gcloud init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d62dacc-6c61-4b33-a332-28c79a1440ca",
   "metadata": {
    "id": "2d62dacc-6c61-4b33-a332-28c79a1440ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya29.a0AeDClZCoiRGzWdJiwYhftjVNuUFS_OmrTgBhEFHb0NPi7PB7Mw5gv6wOsq3KBtFVQK9tFmJkkY4s2WxJMPpTiVPQ-qN58fonAv3Vn-9cM9qntxqjccRRqlkjP0ZhMUOyEiEHEUHs3blb3DJM5RI_nRe-8hmxLNd5Vyw4Z6SdPwaCgYKAU0SARISFQHGX2MiLmQwNKbdW5OW6C6ajyIcOw0177\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default print-access-token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54f6e8-6b62-46bd-88ae-b31b4ff1bb4a",
   "metadata": {
    "id": "9a54f6e8-6b62-46bd-88ae-b31b4ff1bb4a"
   },
   "source": [
    "## Set up Vector Search Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bebda8a-af6e-4602-8afb-5f91cd84b169",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4820,
     "status": "ok",
     "timestamp": 1730940831465,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "5bebda8a-af6e-4602-8afb-5f91cd84b169",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f1d9a612-8aab-447e-c83f-2cfd2ddff235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-google in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-google) (0.5.4)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-google) (0.11.22)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.19.2)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.137.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.27.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (3.20.3)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.9.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.24.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (10.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (4.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.65.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.23.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (4.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.14.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (1.48.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (3.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (24.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-embeddings-google) (0.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-google) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "LZcEBd7LIRJc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5169,
     "status": "ok",
     "timestamp": 1730941105007,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "LZcEBd7LIRJc",
    "outputId": "5fd5c499-27ca-4de1-ee8a-5c0cbc613831"
   },
   "outputs": [],
   "source": [
    "#%pip install llama-index-embeddings-gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7623e698-48fc-4df4-9d46-7db59f7faa17",
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1730941145824,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "7623e698-48fc-4df4-9d46-7db59f7faa17"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from llama_index.embeddings.google import GooglePaLMEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "DGN5AoepNE_f",
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1730942359880,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "DGN5AoepNE_f"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0133b312-cb0d-4312-856c-bf3e60ad868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install llama-index-embeddings-mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0784ae69-5e3b-4b68-ada1-db027c8c7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0bd909cc-9805-44d7-a024-1c7c73909053",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISTRAL_API_KEY= \"nMXQJlfTlws913W7UfjQp3GjFI8KZx80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "74e8fa2f-5a37-4d38-8e22-3bb6a1081ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistral-embed\"\n",
    "embed_model = MistralAIEmbedding(model_name=model_name, api_key=MISTRAL_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "895f7381-7f20-447d-b7dc-785783826b45",
   "metadata": {
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1730941112027,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "895f7381-7f20-447d-b7dc-785783826b45"
   },
   "outputs": [],
   "source": [
    "# setup vector store\n",
    "vector_store = VertexAIVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    index_id=vs_index.name,\n",
    "    endpoint_id=vs_endpoint.name,\n",
    "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
    ")\n",
    "\n",
    "# set storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "48f63284-7717-4faa-8819-19a5deed3f66",
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1730942967292,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "48f63284-7717-4faa-8819-19a5deed3f66"
   },
   "outputs": [],
   "source": [
    "vertex_gemini = Vertex(\n",
    "    model=\"gemini-pro\", temperature=1, additional_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "He8bRkgcNJyd",
   "metadata": {
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1730942393469,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "He8bRkgcNJyd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GeminiEmbedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1344487484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"models/embedding-004\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m embed_model = GeminiEmbedding(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGOOGLE_API_KEY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GeminiEmbedding' is not defined"
     ]
    }
   ],
   "source": [
    "# get API key and create embeddings\n",
    "\n",
    "model_name = \"models/embedding-004\"\n",
    "\n",
    "embed_model = GeminiEmbedding(\n",
    "    model_name=model_name, api_key=GOOGLE_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "338449eb-24a0-45a3-b98b-a392246dee2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1730943303913,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "338449eb-24a0-45a3-b98b-a392246dee2b"
   },
   "outputs": [],
   "source": [
    "# get API key and create embeddings\n",
    "\n",
    "model_name = \"models/embedding-gecko-003\"\n",
    "api_key = GOOGLE_API_KEY\n",
    "\n",
    "embed_model = GooglePaLMEmbedding(model_name=model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b0e5e9b-ec4e-4225-9f17-ba7d514e981c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resource models/textembedding-gecko-001 is not a valid resource ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/238152913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, project, location, credentials, version)\u001b[0m\n\u001b[1;32m   4501\u001b[0m         \u001b[0;31m# Create a versioned model_name, if it exists, for getting the GCA model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4502\u001b[0m         \u001b[0mversioned_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_versioned_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4503\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversioned_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4505\u001b[0m         \u001b[0;31m# Create ModelRegistry with the unversioned resource name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0mShould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m--> 681\u001b[0;31m         resource_name = utils.full_resource_name(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mresource_noun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_noun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/utils/__init__.py\u001b[0m in \u001b[0;36mfull_resource_name\u001b[0;34m(resource_name, resource_noun, parse_resource_name_method, format_resource_name_method, parent_resource_name_fields, project, location, resource_id_validator)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mvalidate_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mresource_id_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     format_args = {\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_revisioned_resource_id_validator\u001b[0;34m(resource_id)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \"\"\"\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^[\\w-]+@?[\\w-]+$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resource {resource_id} is not a valid resource ID.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     def __init__(\n",
      "\u001b[0;31mValueError\u001b[0m: Resource models/textembedding-gecko-001 is not a valid resource ID."
     ]
    }
   ],
   "source": [
    "# Define the model's full resource path (assuming the model is available in this region)\n",
    "model_name = \"models/textembedding-gecko-001\"\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = aiplatform.Model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b3d3a77-b6fa-4b6f-adf2-e5836b60a667",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resource models/textembedding-gecko-004 is not a valid resource ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1290567470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, project, location, credentials, version)\u001b[0m\n\u001b[1;32m   4501\u001b[0m         \u001b[0;31m# Create a versioned model_name, if it exists, for getting the GCA model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4502\u001b[0m         \u001b[0mversioned_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_versioned_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4503\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversioned_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4505\u001b[0m         \u001b[0;31m# Create ModelRegistry with the unversioned resource name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0mShould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0mproject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m--> 681\u001b[0;31m         resource_name = utils.full_resource_name(\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mresource_noun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_noun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/utils/__init__.py\u001b[0m in \u001b[0;36mfull_resource_name\u001b[0;34m(resource_name, resource_noun, parse_resource_name_method, format_resource_name_method, parent_resource_name_fields, project, location, resource_id_validator)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mvalidate_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0mresource_id_validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     format_args = {\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_revisioned_resource_id_validator\u001b[0;34m(resource_id)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \"\"\"\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^[\\w-]+@?[\\w-]+$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Resource {resource_id} is not a valid resource ID.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     def __init__(\n",
      "\u001b[0;31mValueError\u001b[0m: Resource models/textembedding-gecko-004 is not a valid resource ID."
     ]
    }
   ],
   "source": [
    "# Replace with the name of the embedding model from Vertex AI Model Garden\n",
    "model_name = \"models/textembedding-gecko-004\"  # Example model; replace with the model you want\n",
    "\n",
    "# Load the model\n",
    "embedding_model = aiplatform.Model(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28TU8nv-0Gk8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "error",
     "timestamp": 1730941130518,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "28TU8nv-0Gk8",
    "outputId": "2b21c68b-4e1a-465f-f61d-039e79ccf410"
   },
   "outputs": [],
   "source": [
    "# configure embedding model\n",
    "\n",
    "\n",
    "embed_model = VertexTextEmbedding(\n",
    "    model_name=\"textembedding-gecko@003\",\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    credentials = credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5868bb45-eceb-4d58-86a3-a187d36f2b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping llama-index-embeddings-huggingface as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: llama-index-embeddings-instructor 0.2.1\n",
      "Uninstalling llama-index-embeddings-instructor-0.2.1:\n",
      "  Successfully uninstalled llama-index-embeddings-instructor-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall llama-index-embeddings-huggingface llama-index-embeddings-instructor -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cf0e4d7f-a7cd-4d58-9a91-89444017658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.26.2)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (0.11.22)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (2.7.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.10)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.5.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.12.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.0.3)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2023.12.25)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.23.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-embeddings-instructor\n",
      "  Using cached llama_index_embeddings_instructor-0.2.1-py3-none-any.whl.metadata (759 bytes)\n",
      "Requirement already satisfied: instructorembedding<2.0.0,>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (1.0.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (0.11.22)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (2.7.0)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-embeddings-instructor) (2.4.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.10.0)\n",
      "Requirement already satisfied: httpx in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (4.46.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.26.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.16.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (3.1.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/homebrew/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.0.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (24.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2023.12.25)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/homebrew/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (0.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (3.23.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (2.1.5)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->llama-index-embeddings-instructor) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-instructor) (1.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-instructor) (1.2.2)\n",
      "Using cached llama_index_embeddings_instructor-0.2.1-py3-none-any.whl (3.6 kB)\n",
      "Installing collected packages: llama-index-embeddings-instructor\n",
      "Successfully installed llama-index-embeddings-instructor-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-embeddings-instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "055d47d4-8edf-4b79-a2f6-a2d99f8526a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/homebrew/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d1f58e5-9a3b-40c6-a2c2-7462ca4dc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install \"pydantic<2.0\"\n",
    "#%pip install --upgrade llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0748789e-3cd5-4178-acae-074b9dcd2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.46.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.19.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.12.0)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/homebrew/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.26.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/homebrew/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.20.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e7ed066e0b1fd29896a2a716dfd19a50cb34bc3c5fce7bd868a528ceddd73820\n",
      "  Stored in directory: /Users/tubakaraca/Library/Caches/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.7.0\n",
      "    Uninstalling sentence-transformers-2.7.0:\n",
      "      Successfully uninstalled sentence-transformers-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-embeddings-huggingface 0.3.1 requires sentence-transformers>=2.6.1, but you have sentence-transformers 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sentence-transformers-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbc7516c-5cf6-4623-9fbd-7e6696a1886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2b53071d-0d25-42df-b5fe-30d330d47664",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 The Model does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/2559186078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, project, location, credentials, version)\u001b[0m\n\u001b[1;32m   4501\u001b[0m         \u001b[0;31m# Create a versioned model_name, if it exists, for getting the GCA model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4502\u001b[0m         \u001b[0mversioned_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelRegistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_versioned_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4503\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gca_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversioned_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4505\u001b[0m         \u001b[0;31m# Create ModelRegistry with the unversioned resource name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    690\u001b[0m         )\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         return getattr(self.api_client, self._getter_method)(\n\u001b[0m\u001b[1;32m    693\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DEFAULT_RETRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/model_service/client.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 The Model does not exist."
     ]
    }
   ],
   "source": [
    "# Replace with the name of the embedding model from Vertex AI Model Garden\n",
    "model_name = \"textembedding-gecko-\"  # Example model; replace with the model you want\n",
    "\n",
    "# Load the model\n",
    "embedding_model = aiplatform.Model(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70d8ba55-9367-45ca-9e82-456945102df9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbedding' object has no attribute '__pydantic_private__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/3200041715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the embedding model on the specified device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nvidia/NV-Embed-v2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/embeddings/huggingface/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager, **model_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mwill\u001b[0m \u001b[0monly\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mparallel_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mnum_workers\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0membedding\u001b[0m \u001b[0mcalls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOther\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    863\u001b[0m                 )\n\u001b[1;32m    864\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid_field_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_private__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__private_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m                     \u001b[0m_object_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    851\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raises AttributeError if appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HuggingFaceEmbedding' object has no attribute '__pydantic_private__'"
     ]
    }
   ],
   "source": [
    "# Determine the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the embedding model on the specified device\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"nvidia/NV-Embed-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c4cb374c-fd45-4883-a225-546726156165",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbedding' object has no attribute '__pydantic_private__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1023017293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# loads BAAI/bge-small-en-v1.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BAAI/bge-small-en-v1.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/embeddings/huggingface/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, tokenizer_name, pooling, max_length, query_instruction, text_instruction, normalize, model, tokenizer, embed_batch_size, cache_folder, trust_remote_code, device, callback_manager, **model_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     ):\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mcache_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_folder\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget_cache_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    863\u001b[0m                 )\n\u001b[1;32m    864\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid_field_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_private__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__private_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m                     \u001b[0m_object_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    851\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raises AttributeError if appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                         \u001b[0;31m# this is the current error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HuggingFaceEmbedding' object has no attribute '__pydantic_private__'"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# loads BAAI/bge-small-en\n",
    "# embed_model = HuggingFaceEmbedding()\n",
    "\n",
    "# loads BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d4c944d-623c-4122-a3f3-40aad844d402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e675aac7e20407aa7c7eb6d6129f2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1109548611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstructor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInstructorEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membed_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInstructorEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"hkunlp/instructor-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/embeddings/instructor/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, query_instruction, text_instruction, embed_batch_size, cache_folder, device, callback_manager)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         )\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINSTRUCTOR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_embeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_was_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: INSTRUCTOR._load_sbert_model() got an unexpected keyword argument 'token'"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.instructor import InstructorEmbedding\n",
    "\n",
    "embed_model = InstructorEmbedding(model_name=\"hkunlp/instructor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d818f33-8806-4551-b2ff-f7e45d19d92f",
   "metadata": {
    "id": "9f8d5b37-630b-4d0d-930b-06e0325507dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6a0507a7074f41bf2002aa07f5879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de583e623e734cdf9fec0d7d390a12e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0090c8dff104dfa87ee3aff61736430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ac5848e9cf4ae39fac077686b1ef74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14af41245cab46f9b05d3a3c138379de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddea257a02e8489691c735958330370a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e14adfc38646248591618398031f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b84a51a80ba4a7194bb00b8f3ce9a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f364732818ae461384ce8314545f4d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ad653281c541d7874f2228a9716de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588fb9e2d6b34898af49ac54da9ed341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4341b3c4-65ee-4487-b58f-203aa6e10a41",
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1730943308654,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "4341b3c4-65ee-4487-b58f-203aa6e10a41"
   },
   "outputs": [],
   "source": [
    "\n",
    "# setup the index/query process, ie the embedding model (and completion if used)\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = vertex_gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4242d-a0cc-4f47-b4aa-066132ac157d",
   "metadata": {},
   "source": [
    "## Router query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774825a-bc8d-4064-8c6a-dfad2da26539",
   "metadata": {},
   "source": [
    "### Create vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9203e6-9cb3-4df3-82e5-7c8c461b63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud services enable aiplatform.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c59a60f-5b5e-4e38-bc9e-bf9cb0c6659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"GGGR_CompleteReport_2014.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c4e0afef-21ee-4201-8867-222935fec151",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b8a71fbb-3c8f-4b91-8bb9-8296ada55d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fc0c6263-ab76-407c-a050-cc8382e1e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aafac1cb-ed3c-4ef6-9c05-8297be1bf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting datapoints MatchingEngineIndex index: projects/135008850867/locations/europe-west1/indexes/5918794237620518912\n",
      "MatchingEngineIndex index Upserted datapoints. Resource name: projects/135008850867/locations/europe-west1/indexes/5918794237620518912\n"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex(nodes, storage_context = storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d1bfa831-7114-47e8-8bcf-4ed9a94d13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define index from vector store\n",
    "#vector_index = VectorStoreIndex.from_documents(\n",
    "#    documents, storage_context=storage_context\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b7f8a4-c255-4e9b-9376-3b461d644d79",
   "metadata": {},
   "source": [
    "### Create summary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6fcd73e-6a6c-4699-9361-22150dc27485",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_index = SummaryIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12466d-a8f4-4b53-9eef-3f45e334bfa8",
   "metadata": {},
   "source": [
    "### Create query engine from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ee0657ad-f1b1-4742-859f-e8fefbbe5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730986542.591514 10554612 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9db05a2b-b8bd-4775-b125-60c0d6ed3a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730986563.897436 10554612 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.services.enable) PERMISSION_DENIED: Not found or permission denied for service(s): matchingengine.googleapis.com.\n",
      "Help Token: AYJSUtmY51gUvlqD8tC8CSEy3e9Iux_AZNdjBAMZ3J_KX5aBbSZM43e5o-3-NMJCj6gtP5mkUnOQMjaO4yOV3d73LyKgjYqz2PO_H5LNQllSPKCJ. This command is authenticated as tubakadriye17@gmail.com which is the active account specified by the [core/account] property\n",
      "- '@type': type.googleapis.com/google.rpc.PreconditionFailure\n",
      "  violations:\n",
      "  - subject: ?error_code=220002&services=matchingengine.googleapis.com\n",
      "    type: googleapis.com\n",
      "- '@type': type.googleapis.com/google.rpc.ErrorInfo\n",
      "  domain: serviceusage.googleapis.com\n",
      "  metadata:\n",
      "    services: matchingengine.googleapis.com\n",
      "  reason: SERVICE_CONFIG_NOT_FOUND_OR_PERMISSION_DENIED\n"
     ]
    }
   ],
   "source": [
    "!gcloud services enable matchingengine.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be5294ac-c54f-4dc0-b14b-2ef0fca58277",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9179e157-73a5-4ad2-beaf-864c1da21af7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
     ]
    },
    {
     "ename": "ResponseValidationError",
     "evalue": "The model response did not complete successfully.\nFinish reason: 4.\nFinish message: .\nSafety ratings: [category: HARM_CATEGORY_HATE_SPEECH\nprobability: NEGLIGIBLE\nprobability_score: 0.117675781\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.0864257812\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\nprobability: NEGLIGIBLE\nprobability_score: 0.104980469\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.099609375\n, category: HARM_CATEGORY_HARASSMENT\nprobability: NEGLIGIBLE\nprobability_score: 0.146484375\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.101074219\n, category: HARM_CATEGORY_SEXUALLY_EXPLICIT\nprobability: NEGLIGIBLE\nprobability_score: 0.158203125\nseverity: HARM_SEVERITY_LOW\nseverity_score: 0.333984375\n].\nTo protect the integrity of the chat session, the request and response were not added to chat history.\nTo skip the response validation, specify `model.start_chat(response_validation=False)`.\nNote that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseValidationError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1732726067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary_query_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"what's the summary of the document?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/base/base_query_engine.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mstr_or_query_bundle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryBundle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         dispatcher.event(\n\u001b[1;32m     54\u001b[0m             \u001b[0mQueryEndEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr_or_query_bundle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/query_engine/retriever_query_engine.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    177\u001b[0m         ) as query_event:\n\u001b[1;32m    178\u001b[0m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             response = self._response_synthesizer.synthesize(\n\u001b[0m\u001b[1;32m    180\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_bundle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/response_synthesizers/base.py\u001b[0m in \u001b[0;36msynthesize\u001b[0;34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY_STR\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         ) as event:\n\u001b[0;32m--> 241\u001b[0;31m             response_str = self.get_response(\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0mquery_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 text_chunks=[\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/response_synthesizers/tree_summarize.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, query_str, text_chunks, **response_kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     ]\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0msummary_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_async_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36mrun_async_tasks\u001b[0;34m(tasks, show_progress, progress_bar_desc)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks_to_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36masyncio_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# If we're here, there's an existing loop but it's not running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/async_utils.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks_to_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36masync_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             )\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/llms/llm.py\u001b[0m in \u001b[0;36mapredict\u001b[0;34m(self, prompt, **prompt_args)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_chat_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprompt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0mchat_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0machat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36masync_wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             )\n\u001b[1;32m    356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpanDropEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/llms/callbacks.py\u001b[0m in \u001b[0;36mwrapped_async_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 )\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mf_return_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     callback_manager.on_event_end(\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/llms/vertex/base.py\u001b[0m in \u001b[0;36machat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 )\n\u001b[1;32m    382\u001b[0m             )\n\u001b[0;32m--> 383\u001b[0;31m         generation = await acompletion_with_retry(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chat_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/llms/vertex/utils.py\u001b[0m in \u001b[0;36macompletion_with_retry\u001b[0;34m(client, prompt, max_retries, chat, is_gemini, params, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36masync_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0masync_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Preserve attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/llms/vertex/utils.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mtools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gemini_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mgeneration_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             return await generation.send_message_async(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_send_message_async\u001b[0;34m(self, content, generation_config, safety_settings, tools)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m# By default we're not adding incomplete interactions to history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_validator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             self._response_validator(\n\u001b[0m\u001b[1;32m   1368\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m                 \u001b[0mrequest_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_validate_response\u001b[0;34m(response, request_contents, response_chunks)\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0;34m\"Note that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         )\n\u001b[0;32m-> 1076\u001b[0;31m         raise ResponseValidationError(\n\u001b[0m\u001b[1;32m   1077\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mrequest_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_contents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseValidationError\u001b[0m: The model response did not complete successfully.\nFinish reason: 4.\nFinish message: .\nSafety ratings: [category: HARM_CATEGORY_HATE_SPEECH\nprobability: NEGLIGIBLE\nprobability_score: 0.117675781\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.0864257812\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\nprobability: NEGLIGIBLE\nprobability_score: 0.104980469\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.099609375\n, category: HARM_CATEGORY_HARASSMENT\nprobability: NEGLIGIBLE\nprobability_score: 0.146484375\nseverity: HARM_SEVERITY_NEGLIGIBLE\nseverity_score: 0.101074219\n, category: HARM_CATEGORY_SEXUALLY_EXPLICIT\nprobability: NEGLIGIBLE\nprobability_score: 0.158203125\nseverity: HARM_SEVERITY_LOW\nseverity_score: 0.333984375\n].\nTo protect the integrity of the chat session, the request and response were not added to chat history.\nTo skip the response validation, specify `model.start_chat(response_validation=False)`.\nNote that letting blocked or otherwise incomplete responses into chat history might lead to future interactions being blocked by the service."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n",
      "Retrying llama_index.llms.vertex.utils.acompletion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/generate_content_requests_per_minute_per_project_per_base_model with base model: gemini-1.5-pro. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai..\n"
     ]
    }
   ],
   "source": [
    "summary_query_engine.query(\"what's the summary of the document?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39392d13-d212-4db3-a158-b28619efdb74",
   "metadata": {
    "id": "39392d13-d212-4db3-a158-b28619efdb74"
   },
   "source": [
    "###  Building an Agent Reasoning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09283671-a6f8-4afc-865a-52543e78839d",
   "metadata": {
    "id": "09283671-a6f8-4afc-865a-52543e78839d"
   },
   "outputs": [],
   "source": [
    "# TODO: abstract all of this into a function that takes in a PDF file name\n",
    "def get_doc_tools(\n",
    "    file_path: str,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "\n",
    "    # load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    vector_index = VectorStoreIndex(nodes, #.from_documents(documents,\n",
    "         storage_context=storage_context\n",
    "    )\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "\n",
    "    def vector_query(\n",
    "        query: str, page_numbers: Optional[List[str]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
    "\n",
    "        Useful if you have specific questions over the MetaGPT paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page_numbers = page_numbers or []\n",
    "        metadata_dicts = [\n",
    "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "        ]\n",
    "\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts, condition=FilterCondition.OR\n",
    "            ),\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\", fn=vector_query\n",
    "    )\n",
    "\n",
    "    def summary_query(\n",
    "        query: str,\n",
    "    ) -> str:\n",
    "        \"\"\"Perform a summary of document\n",
    "        query (str): the string query to be embedded.\n",
    "        \"\"\"\n",
    "        summary_engine = summary_index.as_query_engine(\n",
    "            response_mode=\"tree_summarize\",\n",
    "            use_async=True,\n",
    "        )\n",
    "\n",
    "        response = summary_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    summary_tool = FunctionTool.from_defaults(\n",
    "        fn=summary_query, name=f\"summary_tool_{name}\"\n",
    "    )\n",
    "\n",
    "    return vector_query_tool, summary_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "icAK2wmbAChJ",
   "metadata": {
    "id": "icAK2wmbAChJ"
   },
   "source": [
    "## Access files from a Google Cloud Storage (GCS) bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95Dg-wjLAR-x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4874,
     "status": "ok",
     "timestamp": 1730941179794,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "95Dg-wjLAR-x",
    "outputId": "bb3e39b3-3f7e-43e4-ee79-7976f5f66e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.18.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ou5oIt1rArfd",
   "metadata": {
    "id": "Ou5oIt1rArfd"
   },
   "source": [
    "#### Set Up Access to the Google Cloud Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "-ukGc4UyAoh-",
   "metadata": {
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1730941220475,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "-ukGc4UyAoh-"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.auth import load_credentials_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "791DlcDZ_Omf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1730938756726,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "791DlcDZ_Omf",
    "outputId": "a7c9e4e1-4589-46ec-c2a0-6063f38a0878"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gender-equity-research-docs'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCS_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pvG6P_vZERN7",
   "metadata": {
    "id": "pvG6P_vZERN7"
   },
   "outputs": [],
   "source": [
    "# Authenticate using the service account key file\n",
    "credentials, project = load_credentials_from_file('gender-equity-navigator-5a54aed4da0b.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1K9AewRyEGCv",
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1730941213976,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "1K9AewRyEGCv"
   },
   "outputs": [],
   "source": [
    "# Initialize the Cloud Storage client with the credentials\n",
    "#client = storage.Client(credentials=credentials, project= PROJECT_ID)\n",
    "\n",
    "# Access the bucket\n",
    "#bucket = client.get_bucket('gender-equity-research-docs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "oIwErHISAzr_",
   "metadata": {
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1730941224846,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "oIwErHISAzr_"
   },
   "outputs": [],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket(GCS_BUCKET_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "TY5mHKmiA7AY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1730941228970,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "TY5mHKmiA7AY",
    "outputId": "47c4f2c8-f25e-48a3-b676-f7eb7b9f8861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender-snapshots/\n",
      "gender-snapshots/GenderSnapshot_2020.pdf\n",
      "gender-snapshots/GenderSnapshot_2022.pdf\n",
      "gender-snapshots/GenderSnapshot_2023.pdf\n",
      "gender-snapshots/GenderSnapshot_2024.pdf\n",
      "gender-snapshots/UNW_GenderSnapshot_2021.pdf\n",
      "gender-snapshots/gender-snapshot_2019.pdf\n",
      "he-for-she/\n",
      "he-for-she/HeForShe Alliance Impact Report 2024.pdf\n",
      "sustainability-development-goals-reports/\n",
      "sustainability-development-goals-reports/The Sustainable Development Goals Report-2016.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2019.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2020.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2021.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2022.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2023.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2024.pdf\n",
      "sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2017.pdf\n",
      "sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2018.pdf\n",
      "un-women-annual-reports/\n",
      "un-women-annual-reports/Agreed_Conclusions_of_the_Commision_on_the_status_of_women_on_the_critical_areas_of_concern_of_the_beijing_platform_for_action-1996-2009.pdf\n",
      "un-women-annual-reports/Annual Report 2013-2014.pdf\n",
      "un-women-annual-reports/Annual_Report_LAC-2014.pdf\n",
      "un-women-annual-reports/Asia Pacific annual report-2014.pdf\n",
      "un-women-annual-reports/ED-annual-report-2023.pdf\n",
      "un-women-annual-reports/ESAR-Report-UN-Women-Transforming-Equality-2012-2015.pdf\n",
      "un-women-annual-reports/Evaluation-annual-report-2017.pdf\n",
      "un-women-annual-reports/MDG-Gender-web-2012.pdf\n",
      "un-women-annual-reports/Making-Every-Woman-and-Girl-Count-annual-report-2017.pdf\n",
      "un-women-annual-reports/TC-annual-report-2015.pdf\n",
      "un-women-annual-reports/UN-Women-AR-2012.pdf\n",
      "un-women-annual-reports/UN-Women-Annual-Report-2014-2015.pdf\n",
      "un-women-annual-reports/UN-Women-Annual-Report-2015-2016.pdf\n",
      "un-women-annual-reports/UN-Women-Annual-Report-2016-2017.pdf\n",
      "un-women-annual-reports/UN-Women-annual-report-2017-2018.pdf\n",
      "un-women-annual-reports/UN-Women-annual-report-2018-2019.pdf\n",
      "un-women-annual-reports/UN-Women-annual-report-2019-2020.pdf\n",
      "un-women-annual-reports/UN-Women-changing-lives-in-Africa-2012.pdf\n",
      "un-women-annual-reports/UNW-AP-Annual-report-2015.pdf\n",
      "un-women-annual-reports/UNW_Annual-Report-2017.pdf\n",
      "un-women-annual-reports/UNwomen-AnnualReport2012-2013.pdf\n",
      "un-women-annual-reports/UNwomen_AnnualReport_2010-2011.pdf\n",
      "un-women-annual-reports/ed-annual-report-2024.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/FGE-Annual-Report-2016.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/FGE-Annual-report-2015.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/FGE-AnnualReport-2014.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/FGE-annual-report-2017-2018.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/Fund-for-Gender-Equality-FGE-annual-report-2018-2019.pdf\n",
      "un-women-annual-reports/fund-for-gender-equality-annual-reports/Fund-for-Gender-Equality-annual-report-2019-2020.pdf\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/Empowerment-accountability-gender-equality-in-humanitarian-action-crisis-response-2018.pdf\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/Empowerment-and-accountability-for-gender-equality-in-humanitarian-action-and-crisis-response-2017.pdf\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/Humanitarian-action-and-disaster-risk-reduction-annual-report-2019.pdf\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/Humanitarian-action-and-disaster-risk-reduction-annual-report-2020.pdf\n",
      "un-women-annual-reports/humaniterien-action-and-disaster-risk-reduction-annual-reports/Humanitarian-action-and-disaster-risk-reduction-annual-report-2021.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-annex-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter1-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter2-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter3-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter4-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter5-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-chapter6-2000.pdf\n",
      "un-women-annual-reports/progress_of_the_worlds_women-preface-2000.pdf\n",
      "un-women-annual-reports/training center_anual_report-2014.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UN-Trust-Fund-Annual-Report-2016.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UN-Trust-Fund-Annual-Report-2017.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UN-Trust-Fund-annual-report-2019.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UN-Trust-Fund-annual-report-2020.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UN-Trust-Fund-annual-report-2021.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UNTF-Annual-Report-2015.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UNTF-annual-report-2018.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UNTFAnnualReport-2010.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/UNTFAnnualReport-2011.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/un-trust-fund-to-end-violence-against-women-annual-report-2022.pdf\n",
      "un-women-annual-reports/un-trustfund-annual-reports/un-trust-fund-to-end-violence-against-women-annual-report-2023.pdf\n",
      "un-women-annual-reports/west and central africa annual report-2014.pdf\n",
      "un-women-annual-reports/women-peace-security-annual-reports/\n",
      "un-women-annual-reports/women-peace-security-annual-reports/Women-peace-and-security-annual-report-2019-2020.pdf\n",
      "un-women-annual-reports/women-peace-security-annual-reports/peace-and-security-annual-report-2022.pdf\n",
      "un-women-annual-reports/women-peace-security-annual-reports/women-peace-security-and-resilience-annual-report-2022.pdf\n",
      "world-economic-forum/\n",
      "world-economic-forum/GGGR_CompleteReport_2014.pdf\n",
      "world-economic-forum/WEF_GGGR_2017.pdf\n",
      "world-economic-forum/WEF_GGGR_2018.pdf\n",
      "world-economic-forum/WEF_GGGR_2020.pdf\n",
      "world-economic-forum/WEF_GGGR_2021.pdf\n",
      "world-economic-forum/WEF_GGGR_2022.pdf\n",
      "world-economic-forum/WEF_GGGR_2023.pdf\n",
      "world-economic-forum/WEF_GGGR_2024.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2006.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2008.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2009.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2010.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2012.pdf\n",
      "world-economic-forum/WEF_GenderGap_Report_2013.pdf\n",
      "world-economic-forum/WEF_Global_Gender_Gap_Report_2016.pdf\n",
      "world-economic-forum/cover.pdf\n"
     ]
    }
   ],
   "source": [
    "## List and Access Files in the Bucket\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "for blob in blobs:\n",
    "    print(blob.name)  # Prints each file name in the bucket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55629e20-de3a-445e-b8ff-5eb4a17d81d8",
   "metadata": {
    "id": "55629e20-de3a-445e-b8ff-5eb4a17d81d8"
   },
   "source": [
    "## Multi-document agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "neHtHdCBFbBO",
   "metadata": {
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1730941233759,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "neHtHdCBFbBO"
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a4d546a-042f-4c15-adbd-a608f2e6091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GCS client and list all files in the bucket\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket(GCS_BUCKET_NAME)\n",
    "blobs = bucket.list_blobs()  # List all blobs with a prefix if specified\n",
    "# Collect blobs into a list to avoid the iterator error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93d0e327-fea6-4c15-a413-8559bb210e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_list = list(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cace47da-1e93-41d7-9d8e-ccaeb3b5be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for blob in blobs:\n",
    "#    if blob.name.endswith(\".pdf\"):\n",
    "#        print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02355fa9-76ab-455f-8e0b-dab051fbedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: abstract all of this into a function that takes in a PDF file name\n",
    "def get_doc_tools(\n",
    "    file_path: str,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "\n",
    "    #VS_INDEX_NAME = f\"{name}_vector_index\"  # @param {type:\"string\"}\n",
    "    #VS_INDEX_ENDPOINT_NAME = f\"{name}_vector_endpoint\"  # @param {type:\"string\"}\n",
    "    #VS_DIMENSIONS = 768\n",
    "\n",
    "    # check if index exists\n",
    "    #indexes = aiplatform.MatchingEngineIndex.list()\n",
    "    #index_names = [\n",
    "    #    index.resource_name\n",
    "    #    for index in indexes\n",
    "    #    if index.display_name == VS_INDEX_NAME\n",
    "    #]\n",
    "\n",
    "    ## create index\n",
    "    #if len(index_names) == 0:\n",
    "    #    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
    "    #    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    #        display_name=VS_INDEX_NAME,\n",
    "    #        dimensions=VS_DIMENSIONS,\n",
    "    #        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    #        approximate_neighbors_count=150,\n",
    "    #        shard_size=\"SHARD_SIZE_SMALL\",\n",
    "    #        index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
    "    #    )\n",
    "    #    print(\n",
    "    #        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
    "    #    )\n",
    "    #else:\n",
    "    #    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
    "    #    print(\n",
    "    #        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
    "    #    )\n",
    "\n",
    "    #Create an endpoint\n",
    "    #endpoints = aiplatform.MatchingEngineIndex.list()\n",
    "    #endpoint_names = [\n",
    "    #    endpoint.resource_name\n",
    "    #    for endpoint in endpoints\n",
    "    #    if endpoint.display_name == VS_INDEX_ENDPOINT_NAME\n",
    "    #]\n",
    "\n",
    "    #if len(endpoint_names) == 0:\n",
    "    #    print(\n",
    "    #        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
    "    #    )\n",
    "    #    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    #        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
    "    #    )\n",
    "    #    print(\n",
    "    #        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
    "    #    )\n",
    "    #else:\n",
    "    #    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    #        index_endpoint_name=endpoint_names[0]\n",
    "    #    )\n",
    "    #    print(\n",
    "    #        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
    "    #    )\n",
    "\n",
    "    #Deploy index to endpoint\n",
    "    # check if endpoint exists\n",
    "    # It takes about 30 minutes to finish\n",
    "    # index_endpoints = [\n",
    "    #     (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
    "    #     for deployed_index in vs_index.deployed_indexes\n",
    "    # ]\n",
    "\n",
    "    # if len(index_endpoints) == 0:\n",
    "    #     print(\n",
    "    #         f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
    "    #     )\n",
    "    #     vs_deployed_index = vs_endpoint.deploy_index(\n",
    "    #         index=vs_index,\n",
    "    #         deployed_index_id=VS_INDEX_NAME,\n",
    "    #         display_name=VS_INDEX_NAME,\n",
    "    #         machine_type=\"e2-standard-16\",\n",
    "    #         min_replica_count=1,\n",
    "    #         max_replica_count=1,\n",
    "    #     )\n",
    "    #     print(\n",
    "    #         f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    #     )\n",
    "    # else:\n",
    "    #     vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    #         index_endpoint_name=index_endpoints[0][0]\n",
    "    #     )\n",
    "    #     print(\n",
    "    #         f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    #     )\n",
    "\n",
    "    # load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    print(f\"Number of nodes: {len(nodes)} for {name} \")\n",
    "\n",
    "    # setup vector store\n",
    "    vector_store = VertexAIVectorStore(\n",
    "        project_id=PROJECT_ID,\n",
    "        region=REGION,\n",
    "        index_id=vs_index.name,\n",
    "        endpoint_id=vs_endpoint.name,\n",
    "        gcs_bucket_name=GCS_BUCKET_NAME,\n",
    "    )\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "    vector_index = VectorStoreIndex(\n",
    "        nodes, storage_context=storage_context\n",
    "    )\n",
    "    \n",
    "    summary_index = SummaryIndex(nodes) #, storage_context\n",
    "\n",
    "    def vector_query(\n",
    "        query: str, page_numbers: Optional[List[str]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
    "\n",
    "        Useful if you have specific questions over the MetaGPT paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page_numbers = page_numbers or []\n",
    "        metadata_dicts = [\n",
    "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "        ]\n",
    "\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts, condition=FilterCondition.OR\n",
    "            ),\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\", fn=vector_query\n",
    "    )\n",
    "\n",
    "    def summary_query(\n",
    "        query: str,\n",
    "    ) -> str:\n",
    "        \"\"\"Perform a summary of document\n",
    "        query (str): the string query to be embedded.\n",
    "        \"\"\"\n",
    "        summary_engine = summary_index.as_query_engine(\n",
    "            response_mode=\"tree_summarize\",\n",
    "            use_async=True,\n",
    "        )\n",
    "\n",
    "        response = summary_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    summary_tool = FunctionTool.from_defaults(\n",
    "        fn=summary_query, name=f\"summary_tool_{name}\"\n",
    "    )\n",
    "\n",
    "    return vector_query_tool, summary_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e045c6-1c76-4f2c-812e-dbcf34bd788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_to_tools_dict ={}\n",
    "# Process each PDF file in the bucket\n",
    "for blob in blob_list:\n",
    "    if blob.name.endswith(\".pdf\"):  # Filter for PDF files\n",
    "        #print(blob.name)\n",
    "        file_name = blob.name.split('/')[-1].split('.')[0]\n",
    "        # Download blob to local file\n",
    "        local_file_path = f\"/tmp/{blob.name.split('/')[-1]}\"\n",
    "        blob.download_to_filename(local_file_path)\n",
    "        print(f\"Getting tools for paper: {file_name}\")\n",
    "        vector_tool, summary_tool = get_doc_tools(local_file_path,file_name)\n",
    "        report_to_tools_dict[file_name] = [vector_tool, summary_tool]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc1db643-5cca-443d-bfaf-8f0aaf56053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: GenderSnapshot_2020\n",
      "Vector Search index GenderSnapshot_2020_vector_index exists with resource name projects/135008850867/locations/europe-west1/indexes/6759841468031959040\n",
      "Creating Vector Search index endpoint GenderSnapshot_2020_vector_endpoint ...\n"
     ]
    },
    {
     "ename": "FailedPrecondition",
     "evalue": "400 Exceeds maximum number of PublicEndpoint(s) allowed for a single Project, which is 15.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"Exceeds maximum number of PublicEndpoint(s) allowed for a single Project, which is 15.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:400a:808::200a%5D:443 {grpc_message:\"Exceeds maximum number of PublicEndpoint(s) allowed for a single Project, which is 15.\", grpc_status:9, created_time:\"2024-11-09T02:46:56.400796+01:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/2257360087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Getting tools for paper: {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvector_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_doc_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mreport_to_tools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvector_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/2615676444.py\u001b[0m in \u001b[0;36mget_doc_tools\u001b[0;34m(file_path, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;34mf\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[0;32m---> 52\u001b[0;31m         vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVS_INDEX_ENDPOINT_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_endpoint_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, display_name, network, public_endpoint_enabled, description, labels, project, location, credentials, request_metadata, sync, enable_private_service_connect, project_allowlist, encryption_spec_key_name, create_request_timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         return cls._create(\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, display_name, network, public_endpoint_enabled, description, labels, project, location, credentials, request_metadata, sync, enable_private_service_connect, project_allowlist, encryption_spec_key_name, create_request_timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mapi_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instantiate_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         create_lro = api_client.create_index_endpoint(\n\u001b[0m\u001b[1;32m    658\u001b[0m             parent=initializer.global_config.common_location_path(\n\u001b[1;32m    659\u001b[0m                 \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_endpoint_service/client.py\u001b[0m in \u001b[0;36mcreate_index_endpoint\u001b[0;34m(self, request, parent, index_endpoint, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    859\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 Exceeds maximum number of PublicEndpoint(s) allowed for a single Project, which is 15."
     ]
    }
   ],
   "source": [
    "report_to_tools_dict ={}\n",
    "# Process each PDF file in the bucket\n",
    "for blob in blob_list:\n",
    "    if blob.name.endswith(\".pdf\"):  # Filter for PDF files\n",
    "        #print(blob.name)\n",
    "        file_name = blob.name.split('/')[-1].split('.')[0]\n",
    "        # Download blob to local file\n",
    "        local_file_path = f\"/tmp/{blob.name.split('/')[-1]}\"\n",
    "        blob.download_to_filename(local_file_path)\n",
    "        print(f\"Getting tools for paper: {file_name}\")\n",
    "        vector_tool, summary_tool = get_doc_tools(local_file_path,file_name)\n",
    "        report_to_tools_dict[file_name] = [vector_tool, summary_tool]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41452-582f-4a6b-8a9b-4e95ef406e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "209f5c3d-957a-499e-8f74-32c12d3b1e8c",
   "metadata": {},
   "source": [
    "### Create indices in google cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f5011be-92f5-41bf-8d6c-22e870420339",
   "metadata": {
    "id": "86d74d23-0f7e-4510-ba87-8927f42a3c7e",
    "outputId": "0760283c-ffcd-4ee2-f12b-930b8b2bea7b"
   },
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Provided filter is not valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Provided filter is not valid.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:400a:808::200a%5D:443 {grpc_message:\"Provided filter is not valid.\", grpc_status:3, created_time:\"2024-11-08T23:53:20.017922+01:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/3574346500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m index_names = [\n\u001b[1;32m      7\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     for index in aiplatform.MatchingEngineIndex.list(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"display_name:{VS_INDEX_NAME}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(cls, filter, order_by, project, location, credentials, parent)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \"\"\"\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m         return cls._list(\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0morder_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_by\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_list\u001b[0;34m(cls, cls_filter, filter, order_by, read_mask, project, location, credentials, parent)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mlist_request\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order_by\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mresource_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_list_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_request\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         return [\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_service/client.py\u001b[0m in \u001b[0;36mlist_indexes\u001b[0;34m(self, request, parent, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1048\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Provided filter is not valid."
     ]
    }
   ],
   "source": [
    "VS_INDEX_NAME = \"gender_equity_vector_search_index\"  # @param {type:\"string\"}\n",
    "VS_INDEX_ENDPOINT_NAME = \"gender_equity_vector_search_endpoint\"  # @param {type:\"string\"}\n",
    "VS_DIMENSIONS = 768\n",
    "\n",
    "# check if index exists\n",
    "index_names = [\n",
    "    index.resource_name\n",
    "    for index in aiplatform.MatchingEngineIndex.list(\n",
    "        filter=f\"display_name:{VS_INDEX_NAME}\"\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "if len(index_names) == 0:\n",
    "    print(f\"Creating Vector Search index {VS_INDEX_NAME} ...\")\n",
    "    vs_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=VS_INDEX_NAME,\n",
    "        dimensions=VS_DIMENSIONS,\n",
    "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "        approximate_neighbors_count=150,\n",
    "        shard_size=\"SHARD_SIZE_SMALL\",\n",
    "        index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} created with resource name {vs_index.resource_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_index = aiplatform.MatchingEngineIndex(index_name=index_names[0])\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c52918-af1e-4374-9ba2-a4b51c80a4bc",
   "metadata": {
    "id": "e34c8ef8-6943-46ff-8379-1de7bed8757c"
   },
   "source": [
    "**Create an endpoint**\n",
    "\n",
    "To use the index, you need to create an index endpoint. It works as a server instance accepting query requests for your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0583e7f-ee82-479e-aaa9-81424c41cfeb",
   "metadata": {
    "id": "4019ca05-2a40-47b1-9dad-55e64d4ff37d",
    "outputId": "ae9cf374-d189-44a9-9069-b2020984f79a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector Search index endpoint gender_equity_vector_search_endpoint ...\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416/operations/4268563898648494080\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416')\n",
      "Vector Search index endpoint gender_equity_vector_search_endpoint created with resource name projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n"
     ]
    }
   ],
   "source": [
    "endpoint_names = [\n",
    "    endpoint.resource_name\n",
    "    for endpoint in aiplatform.MatchingEngineIndexEndpoint.list(\n",
    "        filter=f\"display_name={VS_INDEX_ENDPOINT_NAME}\"\n",
    "    )\n",
    "]\n",
    "\n",
    "if len(endpoint_names) == 0:\n",
    "    print(\n",
    "        f\"Creating Vector Search index endpoint {VS_INDEX_ENDPOINT_NAME} ...\"\n",
    "    )\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=VS_INDEX_ENDPOINT_NAME, public_endpoint_enabled=True\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index endpoint {vs_endpoint.display_name} created with resource name {vs_endpoint.resource_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        index_endpoint_name=endpoint_names[0]\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02123532-3376-46c5-9432-2ca6e5a9b73f",
   "metadata": {
    "id": "72d96adc-bd1e-41d8-97d0-24f7ba141f17"
   },
   "source": [
    "**Deploy index to endpoint**\n",
    "\n",
    "With the index endpoint, deploy the index by specifying a unique deployed index ID.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb83ef-613a-482c-a36e-2f40fcd1c5bf",
   "metadata": {
    "id": "7b40aa12-d17c-431a-93ec-7c0c35468263",
    "outputId": "cb9d39cf-7c81-404a-ee09-a30572142c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Vector Search index gender_equity_vector_search_index at endpoint gender_equity_vector_search_endpoint ...\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416/operations/6786076090348601344\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n",
      "Vector Search index gender_equity_vector_search_index is deployed at endpoint gender_equity_vector_search_endpoint\n"
     ]
    }
   ],
   "source": [
    "# check if endpoint exists\n",
    "# it takes about 30 mins to finish\n",
    "index_endpoints = [\n",
    "    (deployed_index.index_endpoint, deployed_index.deployed_index_id)\n",
    "    for deployed_index in vs_index.deployed_indexes\n",
    "]\n",
    "\n",
    "if len(index_endpoints) == 0:\n",
    "    print(\n",
    "        f\"Deploying Vector Search index {vs_index.display_name} at endpoint {vs_endpoint.display_name} ...\"\n",
    "    )\n",
    "    vs_deployed_index = vs_endpoint.deploy_index(\n",
    "        index=vs_index,\n",
    "        deployed_index_id=VS_INDEX_NAME,\n",
    "        display_name=VS_INDEX_NAME,\n",
    "        machine_type=\"e2-standard-16\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1,\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} is deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    )\n",
    "else:\n",
    "    vs_deployed_index = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        index_endpoint_name=index_endpoints[0][0]\n",
    "    )\n",
    "    print(\n",
    "        f\"Vector Search index {vs_index.display_name} is already deployed at endpoint {vs_deployed_index.display_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e2d5f93-6334-4bfb-a33c-7051f1e7fe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tools for paper: gender-snapshots/GenderSnapshot_2020.pdf\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Provided filter is not valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Provided filter is not valid.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:400a:802::200a%5D:443 {created_time:\"2024-11-08T23:45:03.010035+01:00\", grpc_status:3, grpc_message:\"Provided filter is not valid.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/1407218527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Getting tools for paper: {file_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mvector_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_tool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_doc_tools\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mreport_to_tools_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvector_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/1245643460.py\u001b[0m in \u001b[0;36mget_doc_tools\u001b[0;34m(file_path, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m     index_names = [\n\u001b[1;32m     14\u001b[0m     \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     for index in aiplatform.MatchingEngineIndex.list(\n\u001b[0m\u001b[1;32m     16\u001b[0m         filter=f\"display_name={VS_INDEX_NAME}\")\n\u001b[1;32m     17\u001b[0m     ]\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mlist\u001b[0;34m(cls, filter, order_by, project, location, credentials, parent)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \"\"\"\n\u001b[1;32m   1350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m         return cls._list(\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0morder_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder_by\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36m_list\u001b[0;34m(cls, cls_filter, filter, order_by, read_mask, project, location, credentials, parent)\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mlist_request\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"order_by\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mresource_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_list_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_request\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         return [\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/index_service/client.py\u001b[0m in \u001b[0;36mlist_indexes\u001b[0;34m(self, request, parent, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1048\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Provided filter is not valid."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e30182-a43c-4990-b736-601ace80eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tools = [t for report in blob_list for t in report_to_tools_dict[report]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "997a8b48-bb42-4a7e-aa6a-24a84df1b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indices_for_documents(\n",
    "    blob_list,\n",
    "    prefix: Optional[str] = None,\n",
    "    storage_context = None  # Assuming you pass storage_context here\n",
    ") -> None:\n",
    "    \"\"\"Create and store vector and summary indices from all PDF documents in a GCS bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Name of the GCS bucket.\n",
    "        prefix (Optional[str]): Optional prefix to filter specific files.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Process each PDF file in the bucket\n",
    "    for blob in blob_list:\n",
    "        if blob.name.endswith(\".pdf\"):  # Filter for PDF files\n",
    "            print(blob.name)\n",
    "            # Download blob to local file\n",
    "            local_file_path = f\"/tmp/{blob.name.split('/')[-1]}\"\n",
    "            blob.download_to_filename(local_file_path)\n",
    "\n",
    "            # Load documents and process\n",
    "            documents = SimpleDirectoryReader(input_files=[local_file_path]).load_data()\n",
    "            #print(documents[:10])\n",
    "            splitter = SentenceSplitter(chunk_size=1024)\n",
    "            nodes = splitter.get_nodes_from_documents(documents)\n",
    "            print(f\"Number of nodes: {len(nodes)} for {blob.name} \")\n",
    "\n",
    "            # Create and store the vector index\n",
    "            vector_index = VectorStoreIndex(nodes, storage_context = storage_context)#.from_documents(documents, storage_context=storage_context)\n",
    "            #stored_vector_indices[blob.name] = vector_index\n",
    "\n",
    "            # Create and store the summary index\n",
    "            summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
    "            #stored_summary_indices[blob.name] = summary_index\n",
    "\n",
    "            print(f\"Indices created and stored for {blob.name}\")\n",
    "    return vector_index, summary_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8261fab4-1704-44c5-af3c-d575355f6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = GCS_BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8d68bec4-ac97-41a2-bf3c-8c4414df4d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender-snapshots/GenderSnapshot_2020.pdf\n",
      "Number of nodes: 25 for gender-snapshots/GenderSnapshot_2020.pdf \n",
      "Indices created and stored for gender-snapshots/GenderSnapshot_2020.pdf\n",
      "gender-snapshots/GenderSnapshot_2022.pdf\n",
      "Number of nodes: 33 for gender-snapshots/GenderSnapshot_2022.pdf \n",
      "Indices created and stored for gender-snapshots/GenderSnapshot_2022.pdf\n",
      "gender-snapshots/GenderSnapshot_2023.pdf\n",
      "Number of nodes: 37 for gender-snapshots/GenderSnapshot_2023.pdf \n",
      "Indices created and stored for gender-snapshots/GenderSnapshot_2023.pdf\n",
      "gender-snapshots/GenderSnapshot_2024.pdf\n",
      "Number of nodes: 37 for gender-snapshots/GenderSnapshot_2024.pdf \n",
      "Indices created and stored for gender-snapshots/GenderSnapshot_2024.pdf\n",
      "gender-snapshots/UNW_GenderSnapshot_2021.pdf\n",
      "Number of nodes: 31 for gender-snapshots/UNW_GenderSnapshot_2021.pdf \n",
      "Indices created and stored for gender-snapshots/UNW_GenderSnapshot_2021.pdf\n",
      "gender-snapshots/gender-snapshot_2019.pdf\n",
      "Number of nodes: 24 for gender-snapshots/gender-snapshot_2019.pdf \n",
      "Indices created and stored for gender-snapshots/gender-snapshot_2019.pdf\n",
      "he-for-she/HeForShe Alliance Impact Report 2024.pdf\n",
      "Number of nodes: 77 for he-for-she/HeForShe Alliance Impact Report 2024.pdf \n",
      "Indices created and stored for he-for-she/HeForShe Alliance Impact Report 2024.pdf\n",
      "sustainability-development-goals-reports/The Sustainable Development Goals Report-2016.pdf\n",
      "Number of nodes: 59 for sustainability-development-goals-reports/The Sustainable Development Goals Report-2016.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The Sustainable Development Goals Report-2016.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2019.pdf\n",
      "Number of nodes: 89 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2019.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2019.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2020.pdf\n",
      "Number of nodes: 99 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2020.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2020.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2021.pdf\n",
      "Number of nodes: 97 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2021.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2021.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2022.pdf\n",
      "Number of nodes: 99 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2022.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2022.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2023.pdf\n",
      "Number of nodes: 122 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2023.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2023.pdf\n",
      "sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2024.pdf\n",
      "Number of nodes: 86 for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2024.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/The-Sustainable-Development-Goals-Report-2024.pdf\n",
      "sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2017.pdf\n",
      "Number of nodes: 82 for sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2017.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2017.pdf\n",
      "sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2018.pdf\n",
      "Number of nodes: 48 for sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2018.pdf \n",
      "Indices created and stored for sustainability-development-goals-reports/TheSustainableDevelopmentGoalsReport-2018.pdf\n",
      "un-women-annual-reports/Agreed_Conclusions_of_the_Commision_on_the_status_of_women_on_the_critical_areas_of_concern_of_the_beijing_platform_for_action-1996-2009.pdf\n",
      "Number of nodes: 220 for un-women-annual-reports/Agreed_Conclusions_of_the_Commision_on_the_status_of_women_on_the_critical_areas_of_concern_of_the_beijing_platform_for_action-1996-2009.pdf \n",
      "Indices created and stored for un-women-annual-reports/Agreed_Conclusions_of_the_Commision_on_the_status_of_women_on_the_critical_areas_of_concern_of_the_beijing_platform_for_action-1996-2009.pdf\n",
      "un-women-annual-reports/Annual Report 2013-2014.pdf\n",
      "Number of nodes: 36 for un-women-annual-reports/Annual Report 2013-2014.pdf \n",
      "Indices created and stored for un-women-annual-reports/Annual Report 2013-2014.pdf\n",
      "un-women-annual-reports/Annual_Report_LAC-2014.pdf\n",
      "Number of nodes: 36 for un-women-annual-reports/Annual_Report_LAC-2014.pdf \n",
      "Indices created and stored for un-women-annual-reports/Annual_Report_LAC-2014.pdf\n",
      "un-women-annual-reports/Asia Pacific annual report-2014.pdf\n",
      "Number of nodes: 42 for un-women-annual-reports/Asia Pacific annual report-2014.pdf \n",
      "Indices created and stored for un-women-annual-reports/Asia Pacific annual report-2014.pdf\n",
      "un-women-annual-reports/ED-annual-report-2023.pdf\n",
      "Number of nodes: 29 for un-women-annual-reports/ED-annual-report-2023.pdf \n",
      "Indices created and stored for un-women-annual-reports/ED-annual-report-2023.pdf\n",
      "un-women-annual-reports/ESAR-Report-UN-Women-Transforming-Equality-2012-2015.pdf\n",
      "Number of nodes: 52 for un-women-annual-reports/ESAR-Report-UN-Women-Transforming-Equality-2012-2015.pdf \n",
      "Indices created and stored for un-women-annual-reports/ESAR-Report-UN-Women-Transforming-Equality-2012-2015.pdf\n",
      "un-women-annual-reports/Evaluation-annual-report-2017.pdf\n",
      "Number of nodes: 31 for un-women-annual-reports/Evaluation-annual-report-2017.pdf \n",
      "Indices created and stored for un-women-annual-reports/Evaluation-annual-report-2017.pdf\n",
      "un-women-annual-reports/MDG-Gender-web-2012.pdf\n",
      "Number of nodes: 8 for un-women-annual-reports/MDG-Gender-web-2012.pdf \n",
      "Indices created and stored for un-women-annual-reports/MDG-Gender-web-2012.pdf\n",
      "un-women-annual-reports/Making-Every-Woman-and-Girl-Count-annual-report-2017.pdf\n",
      "Number of nodes: 57 for un-women-annual-reports/Making-Every-Woman-and-Girl-Count-annual-report-2017.pdf \n",
      "Indices created and stored for un-women-annual-reports/Making-Every-Woman-and-Girl-Count-annual-report-2017.pdf\n",
      "un-women-annual-reports/TC-annual-report-2015.pdf\n",
      "Number of nodes: 34 for un-women-annual-reports/TC-annual-report-2015.pdf \n",
      "Indices created and stored for un-women-annual-reports/TC-annual-report-2015.pdf\n",
      "un-women-annual-reports/UN-Women-AR-2012.pdf\n",
      "Number of nodes: 45 for un-women-annual-reports/UN-Women-AR-2012.pdf \n",
      "Indices created and stored for un-women-annual-reports/UN-Women-AR-2012.pdf\n",
      "un-women-annual-reports/UN-Women-Annual-Report-2014-2015.pdf\n",
      "Number of nodes: 41 for un-women-annual-reports/UN-Women-Annual-Report-2014-2015.pdf \n",
      "Indices created and stored for un-women-annual-reports/UN-Women-Annual-Report-2014-2015.pdf\n",
      "un-women-annual-reports/UN-Women-Annual-Report-2015-2016.pdf\n",
      "Number of nodes: 55 for un-women-annual-reports/UN-Women-Annual-Report-2015-2016.pdf \n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2a00:1450:400a:803::200a%5D:443 {created_time:\"2024-11-07T15:17:17.685098+01:00\", grpc_status:8, grpc_message:\"Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/2931728191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_indices_for_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/2103142982.py\u001b[0m in \u001b[0;36mcreate_indices_for_documents\u001b[0;34m(blob_list, prefix, storage_context)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Create and store the vector index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mvector_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorStoreIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.from_documents(documents, storage_context=storage_context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m#stored_vector_indices[blob.name] = vector_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mindex_struct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex_struct\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 index_struct = self.build_index_from_nodes(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnodes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36mbuild_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some nodes are missing content, skipping them...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_index_from_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseNode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mrun_async_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             self._add_nodes_to_index(\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0mindex_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnodes_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mnodes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_with_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mnew_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_get_node_with_embedding\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m         id_to_embed_map = embed_nodes(\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/utils.py\u001b[0m in \u001b[0;36membed_nodes\u001b[0;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \"\"\"\n\u001b[1;32m    137\u001b[0m     \u001b[0mid_to_embed_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mtexts_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mids_to_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/base/embeddings/base.py\u001b[0m in \u001b[0;36mget_text_embedding_batch\u001b[0;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERIALIZED\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 ) as event:\n\u001b[0;32m--> 335\u001b[0;31m                     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                     \u001b[0mresult_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                     event.on_end(\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/embeddings/vertex/base.py\u001b[0m in \u001b[0;36m_get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         )\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/vertexai/language_models/_language_models.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, texts, auto_truncate, output_dimensionality)\u001b[0m\n\u001b[1;32m   2187\u001b[0m         )\n\u001b[1;32m   2188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m         prediction_response = self._endpoint.predict(\n\u001b[0m\u001b[1;32m   2190\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[0m\n\u001b[1;32m   2291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m             prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   2294\u001b[0m                 \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request. https://cloud.google.com/vertex-ai/docs/generative-ai/quotas-genai."
     ]
    }
   ],
   "source": [
    "vector_index, summary_index = create_indices_for_documents(blob_list, storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6dc8b790-4b27-4cd0-9dba-7adfcd0b4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a0ac4-a756-4169-bb36-79a75d3229d2",
   "metadata": {},
   "source": [
    "## Restore indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c09485b-87f7-43ee-a894-0cf3dcd8b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth import load_credentials_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a57b3d7-abf4-43e6-87b3-f2665120de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import load_indices_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1adfe3d0-de60-4f1a-9173-398ba8a53621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7988de70-a733-429b-8271-a67b1fc3987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2afaa117-d1f7-406e-be98-f2a630427eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.vertexaivectorsearch import VertexAIVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e4c2fc1-f18a-4372-947f-5ddee5ecfbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY= \"AIzaSyDeIRtW4T5liuHcz-i_Gj4lk7_k28iPEhU\"\n",
    "GOOGLE_API_KEY = API_KEY  # add your GOOGLE API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "# Project and Storage Constants\n",
    "PROJECT_ID = \"gender-equity-navigator\"\n",
    "REGION = \"europe-west1\"\n",
    "GCS_BUCKET_NAME = \"gender-equity-research-docs\"\n",
    "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET_NAME}\"\n",
    "# The number of dimensions for the textembedding-gecko@003 is 768\n",
    "# If other embedder is used, the dimensions would probably need to change.\n",
    "VS_DIMENSIONS = 768\n",
    "# Vertex AI Vector Search Index configuration\n",
    "# parameter description here\n",
    "# https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex#google_cloud_aiplatform_MatchingEngineIndex_create_tree_ah_index\n",
    "VS_INDEX_NAME = \"gender_equity_vector_search_index\"  # @param {type:\"string\"}\n",
    "VS_INDEX_ENDPOINT_NAME = \"gender_equity_vector_search_endpoint\"  # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e84da4f4-9878-4990-9dce-069d7b26709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3718f571-c72b-4410-bef7-8940d9068c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    VectorStoreIndex,\n",
    "    SummaryIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7e2bb7-eb44-460c-aae4-ace76cfc2a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Search index gender_equity_vector_search_index exists with resource name projects/135008850867/locations/europe-west1/indexes/5918794237620518912\n",
      "Vector Search index endpoint gender_equity_vector_search_endpoint exists with resource name projects/135008850867/locations/europe-west1/indexEndpoints/6059426172859580416\n"
     ]
    }
   ],
   "source": [
    "vs_index = aiplatform.MatchingEngineIndex(index_name=\"5918794237620518912\")\n",
    "\n",
    "vs_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name=\"6059426172859580416\"\n",
    ")\n",
    "print(\n",
    "        f\"Vector Search index {vs_index.display_name} exists with resource name {vs_index.resource_name}\"\n",
    "    )\n",
    "print(\n",
    "        f\"Vector Search index endpoint {vs_endpoint.display_name} exists with resource name {vs_endpoint.resource_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64f2b39-522f-4c4b-8f07-68c64c95479f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.oauth2.service_account.Credentials object at 0x32424d3c0>\n"
     ]
    }
   ],
   "source": [
    "# Authenticate using the service account key file\n",
    "credentials, project = load_credentials_from_file('gender-equity-navigator-5a54aed4da0b.json')\n",
    "print(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fca7848-962d-4a4b-a78e-7b724339b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup vector store\n",
    "vector_store = VertexAIVectorStore(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    index_id=vs_index.name,\n",
    "    endpoint_id=vs_endpoint.name,\n",
    "    gcs_bucket_name=GCS_BUCKET_NAME,\n",
    ")\n",
    "\n",
    "# set storage context\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a445f54-83cf-4a63-b65e-315f2e2e4b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = load_indices_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ca6511-f20b-403e-afee-c2b5c7b2015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18996f70-8ff3-42bf-923b-6cd4bb5ac794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.vertex import VertexTextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "401062a0-4062-4916-940f-bc940cab798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = VertexTextEmbedding(\n",
    "    model_name=\"textembedding-gecko@003\",\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    credentials = credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18813ccf-3a81-4ca4-9355-71c99200c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.vertex import Vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b77c504-4314-49f8-8cfa-afffb8b20911",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_gemini = Vertex(\n",
    "    model=\"gemini-pro\", temperature=1, additional_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "770de25f-5a95-4fa9-9549-50f4d1788410",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83310ad1-e059-4af2-87ef-b15ed898eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb55e6df-4f7e-4b4d-8203-81f71e34c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the index/query process, ie the embedding model (and completion if used)\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = vertex_gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc1193bf-e73e-4270-a9bf-e2e9691582e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = index.as_query_engine(\n",
    "                #service_context=service_context,\n",
    "                similarity_top_k=10,\n",
    "                streaming=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad849672-858b-4b85-a7a7-786064cdd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "602d1402-6909-401f-abb7-3d49b7f8f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from Gender Equity articles and reports over the years.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dce51b97-eaec-44c8-8b61-63a2b9d72155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "113f8b0c-bdb4-42e6-8266-83cc8347abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    [vector_tool],\n",
    "    #tool_retriever=obj_retriever,\n",
    "    llm=vertex_gemini,\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given articles and reports about gender equity.\n",
    "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "511d9479-7da5-48d8-9f56-7967198903c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 55cc99e7-fec0-47bf-93cf-a8775d01d91a. Step input: What is the current status of the gender pay gap according to the Gender Snapshot reports?\n",
      "Added user message to memory: What is the current status of the gender pay gap according to the Gender Snapshot reports?\n",
      "=== LLM Response ===\n",
      "## Current Status of the Gender Pay Gap\n",
      "\n",
      "Here's what I found in the Gender Snapshot reports about the current status of the gender pay gap:\n",
      "\n",
      "* **Globally**: \n",
      "    * The reports show that the \"raw\" pay gap is **23%**. \n",
      "    * This means that women earn **77 cents** for every dollar a man earns globally.\n",
      "    * The reports acknowledge that this gap is likely **underestimated**, as it does not account for factors such as part-time work, occupational segregation, or motherhood.\n",
      "* **In the United States**: \n",
      "    * The \"raw\" pay gap is **16.2%** for full-time workers. \n",
      "    * However, research suggests that the \"adjusted\" pay gap, which controls for factors such as education and experience, is closer to **7%**. \n",
      "    * This means that women in the US earn **93 cents** for every dollar a man earns when we account for these factors.\n",
      "* **Across regions**: \n",
      "    * The pay gap varies considerably across regions, with the largest gaps seen in **Central and Southern Asia** (35%) and the **Arab States** (33%). \n",
      "    * The smallest gaps are seen in **Europe and Central Asia** (12%) and **Latin America and the Caribbean** (17%).\n",
      "\n",
      "## Key Points\n",
      "\n",
      "* The gender pay gap is a persistent problem around the world.\n",
      "* The gap is larger in some regions than others.\n",
      "* The \"adjusted\" pay gap, which accounts for factors such as education and experience, is smaller than the \"raw\" pay gap.\n",
      "* Despite some progress, there is still much work to be done to close the gender pay gap.\n",
      "\n",
      "\n",
      "\n",
      "**Source**: World Bank Gender Snapshot reports. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"What is the current status of the gender pay gap according to the Gender Snapshot reports?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6a4559f-a6ef-431a-9000-fa1692a31ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Current Status of the Gender Pay Gap\n",
      "\n",
      "Here's what I found in the Gender Snapshot reports about the current status of the gender pay gap:\n",
      "\n",
      "* **Globally**: \n",
      "    * The reports show that the \"raw\" pay gap is **23%**. \n",
      "    * This means that women earn **77 cents** for every dollar a man earns globally.\n",
      "    * The reports acknowledge that this gap is likely **underestimated**, as it does not account for factors such as part-time work, occupational segregation, or motherhood.\n",
      "* **In the United States**: \n",
      "    * The \"raw\" pay gap is **16.2%** for full-time workers. \n",
      "    * However, research suggests that the \"adjusted\" pay gap, which controls for factors such as education and experience, is closer to **7%**. \n",
      "    * This means that women in the US earn **93 cents** for every dollar a man earns when we account for these factors.\n",
      "* **Across regions**: \n",
      "    * The pay gap varies considerably across regions, with the largest gaps seen in **Central and Southern Asia** (35%) and the **Arab States** (33%). \n",
      "    * The smallest gaps are seen in **Europe and Central Asia** (12%) and **Latin America and the Caribbean** (17%).\n",
      "\n",
      "## Key Points\n",
      "\n",
      "* The gender pay gap is a persistent problem around the world.\n",
      "* The gap is larger in some regions than others.\n",
      "* The \"adjusted\" pay gap, which accounts for factors such as education and experience, is smaller than the \"raw\" pay gap.\n",
      "* Despite some progress, there is still much work to be done to close the gender pay gap.\n",
      "\n",
      "\n",
      "\n",
      "**Source**: World Bank Gender Snapshot reports. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d411b72-2d9c-475d-91ad-c49a926be3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 64743065-8f5d-488b-9de2-fd83b01b5078. Step input: How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\n",
      "Added user message to memory: How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\n",
      "=== LLM Response ===\n",
      "Sorry, I am unable to look into the future. The context I was trained on only includes information up to 2020, so I wouldn't be able to answer your query on how gender equality indicators evolved from that year onwards.  Would you like me to help with some other tasks?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\n",
    "    \"How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95dc2000-a13c-48aa-a6ef-68fcb6f10c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "missing a required argument: 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/2524093062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwrapt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mid_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{func.__qualname__}-{uuid.uuid4()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_instrument_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m         \"\"\"\n\u001b[0;32m-> 3186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.14_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36m_bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3099\u001b[0m                             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'missing a required argument: {arg!r}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m                             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3101\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3103\u001b[0m                 \u001b[0;31m# We have a positional argument to process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: missing a required argument: 'message'"
     ]
    }
   ],
   "source": [
    "agent.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e515c98f-4819-4bdf-b733-224469899238",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_engine = indices[0].as_query_engine(\n",
    "                #service_context=service_context,\n",
    "                similarity_top_k=10,\n",
    "                streaming=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b45859fb-80ae-42a5-963b-ce46b5640ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = indices[1].as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f3b64357-16d0-4b0d-9d5b-8fc18e189189",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\"Useful for summarization questions related to Gender Equity over the years\"),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from Gender Equity articles and reports over the years.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1f880198-93cf-4770-96bc-7ec540adbe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    #tool_retriever=obj_retriever,\n",
    "    llm=vertex_gemini,\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given articles and reports about gender equity.\n",
    "Please use the tools provided to answer a question as possible. Do not rely on prior knowledge. Summarize your answer\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e17be-eeeb-451a-a26c-e56639c383eb",
   "metadata": {},
   "source": [
    "Gender-Specific Questions\n",
    "Gender Gap Analysis\n",
    "\n",
    "\"What is the current status of the gender pay gap according to the Gender Snapshot reports?\"\n",
    "\"How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\"\n",
    "\"Can you summarize the progress in women's employment in 2023 compared to 2022?\"\n",
    "\"What is the gender distribution in educational attainment in 2024 based on the Gender Snapshot?\"\n",
    "\n",
    "Gender Equality in Sustainable Development Goals\n",
    "\n",
    "\"Which SDGs (Sustainable Development Goals) focus on gender equality according to the 2023 SDG report?\"\n",
    "\"How does gender equality contribute to the achievement of the 2030 SDG agenda, as stated in the 2023 report?\"\n",
    "Gender and Development Reports\n",
    "\n",
    "\"What are the key findings about gender inclusion in education from the 'UN Women Annual Report 2023'?\"\n",
    "\"What does the 2022 SDG report say about gender parity in leadership roles?\"\n",
    "\"How does the 'HeForShe Alliance Impact Report 2024' address the role of men in achieving gender equality?\"\n",
    "SDG and Sustainability Questions\n",
    "Sustainability Goals and Gender\n",
    "\n",
    "\"How does gender inequality impact sustainability goals according to the 2024 SDG report?\"\n",
    "\"Which areas need the most improvement in gender equity to meet the SDGs by 2030?\"\n",
    "\"What are the key challenges in achieving gender equality within the sustainability development goals?\"\n",
    "Data and Statistics\n",
    "\n",
    "\"Can you give a breakdown of gender statistics in the 'UN Women Annual Report 2017'?\"\n",
    "\"What are the main takeaways from the 'The Sustainable Development Goals Report 2020' regarding gender equality?\"\n",
    "\"How has gender equality progressed in the Asia-Pacific region as per the 2014 UN Women Annual Report?\"\n",
    "Regional and International Insights\n",
    "Regional Gender Equality Insights\n",
    "\n",
    "\"What are the gender inequality issues faced by women in the Asia-Pacific region as described in the 2014 report?\"\n",
    "\"According to the 'UNW Gender Snapshot 2021', what are the most pressing gender issues in sub-Saharan Africa?\"\n",
    "\"How do regional variations in gender equality impact global SDG efforts?\"\n",
    "Global Gender Challenges\n",
    "\n",
    "\"What are the main global challenges regarding gender equality identified in the 'Gender Snapshot 2023'?\"\n",
    "\"How does the 'Beijing Platform for Action' address global gender issues, especially concerning education and employment?\"\n",
    "Social and Economic Dimensions\n",
    "Economic Empowerment\n",
    "\n",
    "\"What does the Gender Snapshot 2020 say about women's economic empowerment?\"\n",
    "\"How has women's economic participation changed in the last five years, according to the Gender Snapshot reports?\"\n",
    "Health and Safety\n",
    "\n",
    "\"How does the 'UN Women Annual Report' discuss women's health and safety?\"\n",
    "\"What measures are suggested in the 2024 SDG report to enhance women's health outcomes?\"\n",
    "Women’s Rights and Advocacy\n",
    "\n",
    "\"What strategies are highlighted in the 'HeForShe Alliance Impact Report 2024' to enhance women's rights?\"\n",
    "\"What progress has been made on preventing gender-based violence, according to the 'UN Women Annual Report 2023'?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "207cd6df-020a-4b2b-b086-5472cae7dace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 02d98efe-2fa5-4eab-8b0a-6a21c38dc950. Step input: What is the current status of the gender pay gap according to the Gender Snapshot reports?\n",
      "Added user message to memory: What is the current status of the gender pay gap according to the Gender Snapshot reports?\n",
      "=== LLM Response ===\n",
      "I am sorry, I do not have access to the internet including most recent Gender Snapshot reports about the gender pay gap. However, according to the United States Bureau of Labor Statistics, as of 2022, women earned 82.3 cents for every dollar earned by men, which represents a decrease from 83.4 cents in 2019. In addition, the World Bank reports that the global gender pay gap is estimated to be 23%, meaning that women earn 77% of what men earn globally. These statistics highlight the persistence of the gender pay gap and the need for continued efforts to close it.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"What is the current status of the gender pay gap according to the Gender Snapshot reports?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "072011e9-8264-4900-bf34-dcd10b03033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step ea813cd8-669a-4112-a66d-ad0c795c6f95. Step input: How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\n",
      "Added user message to memory: How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\n",
      "=== LLM Response ===\n",
      "## Evolution of Gender Equality Indicators in the Gender Snapshot Series (2020-2024)\n",
      "\n",
      "While I don't have access to real-time information after November 2023, I can provide insights into the evolution of gender equality indicators from 2020 to 2024 based on the provided Gender Snapshot series reports. \n",
      "\n",
      "Here's a summary of the observed trends:\n",
      "\n",
      "**Positive Developments:**\n",
      "\n",
      "* **Education:** The gender gap in primary and secondary education enrollment has narrowed significantly. More girls are now completing primary and secondary education compared to 2020.\n",
      "* **Labor Force Participation:** More women are actively participating in the labor force, with the global female labor force participation rate increasing by 1.5% between 2020 and 2024.\n",
      "* **Political Representation:** The number of women holding political positions has increased, although the overall representation remains low and varies significantly across countries.\n",
      "* **Access to Healthcare:**  Improvements in access to healthcare have been observed for women and girls, particularly in areas like maternal healthcare and family planning services.\n",
      "\n",
      "**Challenges Remain:**\n",
      "\n",
      "* **Wage Gap:**  Despite increased labor force participation, the gender pay gap persists across all sectors and regions. Women still earn significantly less than men for similar work.\n",
      "* **Violence Against Women:**  Violence against women continues to be a major concern, with 1 in 3 women globally experiencing some form of violence in their lifetime.\n",
      "* **Economic Empowerment:** Women continue to face challenges in accessing economic resources and opportunities, leading to an underrepresentation in leadership roles and ownership of businesses.\n",
      "* **Unpaid Care Work:** The burden of unpaid care work, such as childcare and housework, still falls disproportionately on women, limiting their ability to participate equally in the labor force and public life.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "The Gender Snapshot series highlights encouraging progress in closing the gender gap across various indicators. However, significant challenges remain, and sustained efforts are crucial to achieve genuine gender equality in all spheres of life. \n",
      "\n",
      "It's important to note that these are general trends and the specific situation may vary depending on the region, country, and individual circumstances. \n",
      "\n",
      "For a more detailed analysis, it would be helpful to specify which particular Gender Snapshot reports you are referring to and which specific indicators you are interested in. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"How have gender equality indicators evolved from 2020 to 2024 in the Gender Snapshot series?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a55981cc-e489-4806-bf5c-627113609510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Evolution of Gender Equality Indicators in the Gender Snapshot Series (2020-2024)\n",
      "\n",
      "While I don't have access to real-time information after November 2023, I can provide insights into the evolution of gender equality indicators from 2020 to 2024 based on the provided Gender Snapshot series reports. \n",
      "\n",
      "Here's a summary of the observed trends:\n",
      "\n",
      "**Positive Developments:**\n",
      "\n",
      "* **Education:** The gender gap in primary and secondary education enrollment has narrowed significantly. More girls are now completing primary and secondary education compared to 2020.\n",
      "* **Labor Force Participation:** More women are actively participating in the labor force, with the global female labor force participation rate increasing by 1.5% between 2020 and 2024.\n",
      "* **Political Representation:** The number of women holding political positions has increased, although the overall representation remains low and varies significantly across countries.\n",
      "* **Access to Healthcare:**  Improvements in access to healthcare have been observed for women and girls, particularly in areas like maternal healthcare and family planning services.\n",
      "\n",
      "**Challenges Remain:**\n",
      "\n",
      "* **Wage Gap:**  Despite increased labor force participation, the gender pay gap persists across all sectors and regions. Women still earn significantly less than men for similar work.\n",
      "* **Violence Against Women:**  Violence against women continues to be a major concern, with 1 in 3 women globally experiencing some form of violence in their lifetime.\n",
      "* **Economic Empowerment:** Women continue to face challenges in accessing economic resources and opportunities, leading to an underrepresentation in leadership roles and ownership of businesses.\n",
      "* **Unpaid Care Work:** The burden of unpaid care work, such as childcare and housework, still falls disproportionately on women, limiting their ability to participate equally in the labor force and public life.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "The Gender Snapshot series highlights encouraging progress in closing the gender gap across various indicators. However, significant challenges remain, and sustained efforts are crucial to achieve genuine gender equality in all spheres of life. \n",
      "\n",
      "It's important to note that these are general trends and the specific situation may vary depending on the region, country, and individual circumstances. \n",
      "\n",
      "For a more detailed analysis, it would be helpful to specify which particular Gender Snapshot reports you are referring to and which specific indicators you are interested in. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "62ced601-d8c8-406f-8432-c0e43fca6151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8dc69378-4838-4cb4-a4d2-f272d509feb4. Step input: Can you summarize the progress in women's employment in 2023 compared to 2022?\n",
      "Added user message to memory: Can you summarize the progress in women's employment in 2023 compared to 2022?\n",
      "=== LLM Response ===\n",
      "Overall, the global situation for women in the labor force in 2023 did not experience notable advancement despite initial projections for substantial progress following the negative impact of the pandemic.\n",
      "\n",
      "Although there was an increase in the female labor force participation rate, it primarily reflected women re-entering the workforce after having exited during the pandemic. This increase did not translate into significant gains in terms of closing the gender gap in labor force participation.\n",
      "\n",
      "Moreover, the types of jobs women were able to secure often involved precarious working conditions, characterized by low pay and a lack of social protection. This highlights the ongoing challenge of ensuring decent work opportunities for women.\n",
      "\n",
      "It is important to note that the available data for 2023 is still limited, and further analysis is needed to provide a more comprehensive understanding of the situation. However, the initial reports suggest that despite some positive developments, significant challenges remain in achieving gender equality in the labor market.\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\n",
    "    \"Can you summarize the progress in women's employment in 2023 compared to 2022?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ec87566a-21c2-47a0-912a-6ff9e52e3025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 4381b0af-5876-4284-8f3e-f925f3ebc79f. Step input: What is the gender distribution in educational attainment in 2023 based on the Gender Snapshot?\n",
      "Added user message to memory: What is the gender distribution in educational attainment in 2023 based on the Gender Snapshot?\n",
      "=== LLM Response ===\n",
      "## Gender Distribution in Educational Attainment in 2023: A Snapshot\n",
      "\n",
      "Based on the information available in the Gender Snapshot 2023, here's an overview of the gender distribution in educational attainment:\n",
      "\n",
      "**Global Trends:**\n",
      "\n",
      "* **Women surpass men in educational attainment:**\n",
      "    * Women hold the majority of tertiary degrees (54.2%).\n",
      "    * Men hold a slight majority of upper secondary degrees (51.1%).\n",
      "    * The gender gap favors women at all levels of education.\n",
      "\n",
      "**Regional Variations:**\n",
      "\n",
      "* **Developed regions:** \n",
      "    * Women hold a larger share of tertiary degrees (58.9%).\n",
      "    * The gender gap is most pronounced in favor of women in upper secondary and tertiary education.\n",
      "* **Developing regions:** \n",
      "    * Women hold a smaller share of tertiary degrees (49.9%).\n",
      "    * The gender gap is smaller at all levels of education.\n",
      "\n",
      "**Specific Examples:**\n",
      "\n",
      "* **In Sub-Saharan Africa:**\n",
      "    * Women hold 46.8% of tertiary degrees, showing progress towards closing the gender gap.\n",
      "    * The gender gap in upper secondary attainment is also narrowing.\n",
      "* **In Latin America and the Caribbean:**\n",
      "    * Women hold 60.8% of tertiary degrees, surpassing men significantly.\n",
      "    * The gender gap in upper secondary attainment is also in favor of women.\n",
      "\n",
      "**Additional Notes:**\n",
      "\n",
      "* The data presented highlights the overall trend of women's increasing participation in education.\n",
      "* The specific figures and regional variations may differ depending on the source and methodology used.\n",
      "* It's crucial to consider factors like income level, cultural context, and access to educational resources when analyzing gender disparities in education.\n",
      "\n",
      "**Overall, the Gender Snapshot 2023 paints a positive picture of women's increasing educational attainment globally. However, there are still regional disparities and inequalities that require attention to ensure equal access to education for all individuals.** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"What is the gender distribution in educational attainment in 2023 based on the Gender Snapshot?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5f39f045-53b0-4fe0-b27d-291e5f580ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 5ae7893f-cac1-4790-a31a-c1b0676e1846. Step input: Which SDGs (Sustainable Development Goals) focus on gender equality according to the 2023 SDG report?\n",
      "Added user message to memory: Which SDGs (Sustainable Development Goals) focus on gender equality according to the 2023 SDG report?\n",
      "=== LLM Response ===\n",
      "## SDGs related to Gender Equality\n",
      "\n",
      "According to the 2023 SDG report, several goals directly contribute to achieving gender equality:\n",
      "\n",
      "* **Goal 5: Achieve gender equality and empower all women and girls:** This goal explicitly addresses gender disparities and aims to empower women and girls in all areas of life, including education, health, economic participation, and political representation. \n",
      "* **Goal 1: End poverty in all its forms everywhere:** This goal recognizes the disproportionate impact of poverty on women and girls and emphasizes the need for inclusive economic growth that empowers women and promotes equal access to resources and opportunities.\n",
      "* **Goal 4: Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all:** This goal acknowledges the importance of education for girls and women in breaking the cycle of poverty and achieving gender equality.\n",
      "* **Goal 8: Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all:** This goal aims to create decent work opportunities for women and promote equal pay for equal work.\n",
      "* **Goal 10: Reduce inequality within and among countries:** This goal recognizes that gender inequality contributes to broader inequalities within and between countries and calls for policies that promote equality and social justice for all.\n",
      "* **Goal 16: Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels:** This goal addresses the need to eliminate gender-based violence and discrimination and ensure equal access to justice for all. \n",
      "\n",
      "While these are the primary SDGs directly linked to gender equality, other goals also have significant implications for achieving this objective. For instance, **Goal 3 (Good Health and Well-being)** aims to ensure healthy lives and promote well-being for all ages, including addressing specific health issues that disproportionately affect women and girls. Similarly, **Goal 6 (Clean Water and Sanitation)** recognizes the importance of access to clean water and sanitation for women and girls, particularly in rural areas. \n",
      "\n",
      "Therefore, achieving gender equality requires a comprehensive approach that addresses the multifaceted issues faced by women and girls across various domains. The SDGs provide a framework for coordinated action across different sectors and stakeholders to achieve this crucial goal. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent.query(\"Which SDGs (Sustainable Development Goals) focus on gender equality according to the 2023 SDG report?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "GUrYfF7uJUCs",
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1730941235188,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "GUrYfF7uJUCs"
   },
   "outputs": [],
   "source": [
    "# TODO: abstract all of this into a function that takes in a PDF file name\n",
    "def get_doc_tools(\n",
    "    file_path: str,\n",
    "    name: str,\n",
    ") -> str:\n",
    "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
    "\n",
    "    # load documents\n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context\n",
    "    )\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "\n",
    "    def vector_query(\n",
    "        query: str, page_numbers: Optional[List[str]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
    "\n",
    "        Useful if you have specific questions over the MetaGPT paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "\n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        page_numbers = page_numbers or []\n",
    "        metadata_dicts = [\n",
    "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
    "        ]\n",
    "\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts, condition=FilterCondition.OR\n",
    "            ),\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f\"vector_tool_{name}\", fn=vector_query\n",
    "    )\n",
    "\n",
    "    def summary_query(\n",
    "        query: str,\n",
    "    ) -> str:\n",
    "        \"\"\"Perform a summary of document\n",
    "        query (str): the string query to be embedded.\n",
    "        \"\"\"\n",
    "        summary_engine = summary_index.as_query_engine(\n",
    "            response_mode=\"tree_summarize\",\n",
    "            use_async=True,\n",
    "        )\n",
    "\n",
    "        response = summary_engine.query(query)\n",
    "        return response\n",
    "\n",
    "    summary_tool = FunctionTool.from_defaults(\n",
    "        fn=summary_query, name=f\"summary_tool_{name}\"\n",
    "    )\n",
    "\n",
    "    return vector_query_tool, summary_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2eba8a2-3c21-4956-bea7-eace93ecdb65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_31388/3251957780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'blobs' is not defined"
     ]
    }
   ],
   "source": [
    "blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ced8dc27-ff83-4880-bf4a-684e04c4a993",
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1730943004810,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "ced8dc27-ff83-4880-bf4a-684e04c4a993"
   },
   "outputs": [],
   "source": [
    "def get_doc_tools_for_bucket(\n",
    "    bucket_name: str,\n",
    "    prefix: Optional[str] = None,\n",
    ") -> List[tuple]:\n",
    "    \"\"\"Get vector and summary tools from all PDF documents in a GCS bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Name of the GCS bucket.\n",
    "        prefix (Optional[str]): Optional prefix to filter specific files.\n",
    "\n",
    "    Returns:\n",
    "        List[tuple]: A list of tuples containing vector and summary tools for each file.\n",
    "    \"\"\"\n",
    "    # Initialize GCS client and list all files in the bucket\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)  # List all blobs with a prefix if specified\n",
    "\n",
    "    # Store tools for each document\n",
    "    tools = []\n",
    "\n",
    "    # Process each PDF file in the bucket\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\".pdf\"):  # Filter for PDF files\n",
    "            # Download blob to local file\n",
    "            local_file_path = f\"/tmp/{blob.name.split('/')[-1]}\"\n",
    "            blob.download_to_filename(local_file_path)\n",
    "\n",
    "            # Load documents and process\n",
    "            documents = SimpleDirectoryReader(input_files=[local_file_path]).load_data()\n",
    "            print(documents[:10])\n",
    "            splitter = SentenceSplitter(chunk_size=1024)\n",
    "            nodes = splitter.get_nodes_from_documents(documents)\n",
    "            vector_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "            summary_index = SummaryIndex(nodes)\n",
    "\n",
    "            # Define vector and summary query functions\n",
    "            def vector_query(query: str, page_numbers: Optional[List[str]] = None) -> str:\n",
    "                page_numbers = page_numbers or []\n",
    "                metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "                query_engine = vector_index.as_query_engine(\n",
    "                    similarity_top_k=2,\n",
    "                    filters=MetadataFilters.from_dicts(\n",
    "                        metadata_dicts, condition=FilterCondition.OR\n",
    "                    ),\n",
    "                )\n",
    "                response = query_engine.query(query)\n",
    "                return response\n",
    "\n",
    "            vector_query_tool = FunctionTool.from_defaults(\n",
    "                name=f\"vector_tool_{blob.name}\", fn=vector_query\n",
    "            )\n",
    "\n",
    "            def summary_query(query: str) -> str:\n",
    "                summary_engine = summary_index.as_query_engine(\n",
    "                    response_mode=\"tree_summarize\",\n",
    "                    use_async=True,\n",
    "                )\n",
    "                response = summary_engine.query(query)\n",
    "                return response\n",
    "\n",
    "            summary_tool = FunctionTool.from_defaults(\n",
    "                fn=summary_query, name=f\"summary_tool_{blob.name}\"\n",
    "            )\n",
    "\n",
    "            # Append the tools for the current file\n",
    "            tools.append((vector_query_tool, summary_tool))\n",
    "\n",
    "    return tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74a8bcc7-d50b-4b50-a7f7-9b2cd80237a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HTTPIterator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/326442947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'HTTPIterator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "local_file_path = f\"/tmp/{blob.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "sm4w300ILQre",
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1730941955536,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "sm4w300ILQre"
   },
   "outputs": [],
   "source": [
    "# List available models (specifically for Text Embeddings, or general models)\n",
    "models = aiplatform.Model.list()\n",
    "\n",
    "# Print out the names of the available models\n",
    "for model in models:\n",
    "    print(model.display_name)  # This will display the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "SJXbZSwtEht7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 6498,
     "status": "error",
     "timestamp": 1730943330031,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "SJXbZSwtEht7",
    "outputId": "e2abda46-d08f-41e9-eed7-05e5148488db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='cb43076a-3332-4a04-810b-0fd43dc759e6', embedding=None, metadata={'page_label': '1', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='PROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS\\nTHE GENDER SNAPSHOT 2020', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='876623d0-f5b6-422a-894a-2a8bb0aad678', embedding=None, metadata={'page_label': '2', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2\\nPROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS \\nSnapshot of gender equality across the Sustainable Development Goals\\n2PROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS\\nThe COVID-19 pandemic \\nis causing a resurgence in extreme poverty, affecting women the most. By 2021, around \\n435 million\\nWOMEN AND GIRLS\\nwill be living on less than $1.90 a day — including \\n47 million \\npushed into poverty as a result of COVID-19.\\nGlobally, women have a \\n27% \\nHIGHER RISK \\nthan men of facing severe food insecurity. This gender gap is \\nexpected to rise in the \\nwake of the pandemic.Women health-care workers are on the front lines of the COVID-19 pandemic and are at increased risk of exposure to the virus. \\nAmong infected health-\\ncare workers in five countries with available data,\\n72% \\nwere women.Women spend \\n3x \\nas many hours as men each day in unpaid care and domestic work. COVID-19 is adding to women’s unpaid care workloads. \\nWorldwide, \\n1 in 4 \\nPARLIAMENTARY SEATS \\nare held by women. At the \\nlocal level, women hold\\n36% \\nOF ELECTED SEATS \\nin local deliberative bodies. \\nBased on data from 57 \\ncountries, \\n3 in 4 \\nWOMEN \\nreport making their own \\ndecisions about their personal health care or on whether or not to have sex.\\nSchool closures are likely to increase gender gaps in education. More than\\n11 million \\nGIRLS \\n– from pre-primaryschool to tertiaryeducation age – are at\\nrisk of not returning to\\nschool in 2020.An estimated\\n243 million \\nWOMEN AND GIRLS  \\naged 15 to 49 were subjected to sexual and/or physical violence by an intimate partner in the previous year. \\nAt least \\n200 \\nmillion \\nGIRLS AND WOMEN \\nhave been subjected to \\nfemale genital mutilation (FGM), according to recent data from 31 countries where this practice is concentrated.\\nGlobally, \\n1 in 5\\nWOMEN  \\n20 to 24 years of \\nage were married in childhood. \\nChild marriage and FGM \\nwere on a downward trajectory before the pandemic hit. However, economic hardship and \\nschool disruptions could \\nderail progress. 4 in 10\\nSCHOOLS AROUND THE WORLD  and ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e57afe70-e9d9-4062-ade2-5356f5741ea8', embedding=None, metadata={'page_label': '3', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='3\\nTHE GENDER SNAPSHOT 2020\\nSnapshot of gender equality across the Sustainable Development Goals\\n3THE GENDER SNAPSHOT 2020\\nLack of clean cooking \\nfuels and technologies accounted for almost \\n2 million \\npremature deaths among women and girls in 2016.The manufacturing sector has suffered major job losses and contraction in economic output due to the pandemic. Women are\\nmore likely \\nthan men to be engaged \\nin vulnerable employment in that sector and are more at risk of losing their manufacturing jobs or livelihoods.\\nDomestic workers and those employed in the informal economy have been especially hard hit by the pandemic. Nearly Women with disabilities face multiple forms of discrimination. \\n3 in 10 \\nWOMEN AND MEN  \\nWITH DISABILITIES Safe and reliable public transportation can be a lifeline for poor urban women, but access remains inadequate in many urban settings. Data from 2019 showed that only \\n50%\\nof the world’s urban population had convenient access to public transport. \\nWomen and girls bear the brunt of increasing climate-related disasters, but are rarely in a position to effect change. At the United Nations Climate Change Conference COP 25, only\\n \\n21%\\nof heads of delegation were women.In countries led by women, confirmed deaths from COVID-19 are six times lower. Likewise, women’s direct participation in peace processes has shown to be a building block for lasting agreements. Yet, between 1992 and 2019, women made up only \\n6%  OF MEDIATORS,\\n6% \\n13% OF NEGOTIATORS\\nin peace processes.\\nGlobally, \\n4.1 billion\\nPEOPLE are now online, \\nbut only 48% of the world’s \\nfemale population are using the Internet, compared to 58% of men. That gender \\ngap is increasing in some \\ndeveloping regions.70% \\nOF THOSE IN LEAST DEVELOPED COUNTRIES  \\nface challenges in providing basic hygiene facilities for students. In some countries, \\n150 or more\\nSCHOOLGIRLS \\nare expected to share a single toilet.72% \\nof domestic workers, most of whom are women, have suffered job losses or reduced hours. personally experienced at least one form of discrimination between 2014 and 2019.\\nOF SIGNATORIES\\nand ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='3d7ec17d-f12d-4076-a711-94ea92f8b262', embedding=None, metadata={'page_label': '4', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4\\nPROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS LEAVE NO WOMAN \\nOR GIRL BEHIND\\nThe COVID-19 pandemic reveals and exacerbates fault lines of inequality \\nThe pandemic is eroding health systems, disrupting \\nroutine health services, deteriorating labour markets and limiting access to nutritious diets. And the world’s poorest people are bearing the brunt of the crisis. Hundreds of thousands of additional deaths among children under age 5 are expected in 2020, along with tens of thousands of additional maternal deaths. According to a recent study, if routine health care is disrupted and access to food is decreased, the increase in child and maternal deaths could be devastating: 118 low- and middle-income countries could see an increase of 9.8 to 44.7 per cent in under-5 deaths per month and an 8.3 to 38.6 per cent rise in maternal deaths per month. At the intersection of many deprivations are women and girls living in poverty, migrants, refugees, asylum seekers, and internally displaced persons, who face the greatest hardships. Even before the pandemic, these groups were dealing with food insecurity due to insufficient income; they routinely confronted challenges in accessing essential health services and were excluded from social protection systems, where they existed.\\nAdditional maternal and child deaths attributed to indirect effects of the COVID-19 \\npandemic, forecasts and modelled estimates, over 12 months (percentage and number)IN FOCUS\\nMATERNAL DEATHS CHILD DEATHS Projected % increase in maternal & child deaths 44.7%\\n38.6%\\n14.7%\\n8.3%2,313,900 \\nprojected additional deathsHIGH  SCENARIO\\nMEDIUM  \\nSCENARIO\\nLOW  \\nSCENARIO894,400 \\nprojected additional deaths\\n506,900 \\nprojected additional deaths 17.3%\\n9.8%LOW  \\nSCENARIOMEDIUM  \\nSCENARIO43,100 \\nprojected additional deaths113,400 \\nprojected additional deathsHIGH  SCENARIO\\n24,400 \\nprojected additional deaths\\nSource: Roberton, T., et al., ‘Early Estimates of the Indirect Effects of the COVID-19 Pandemic on Maternal and Child Mortality in Low-Income and Middle-Income Countries: A Modelling Study’, The Lancet Global Health, May 2020. \\nNote: The three scenarios are based on coverage reductions in family planning services, antenatal, childbirth and postnatal care services, and early child \\nvaccination, preventive and curative services. It is assumed that four health system components affect the coverage of services: availability of health workers, availability of supplies and equipment, demand for services, and access to services. The child deaths include the effects of increased wasting.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='e53137ae-b816-4230-8f8b-922e2f172507', embedding=None, metadata={'page_label': '5', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='5\\nTHE GENDER SNAPSHOT 2020Economic and social disparities, including inequalities in \\neducation, living conditions, and a greater likelihood to be employed in insecure and low-paying jobs, make some groups more vulnerable to the pandemic than others. As of mid-September 2020, more than 29 million cases of COVID-19 had been confirmed globally and were climbing each day; over 900,000 people had succumbed to the virus. The pandemic is affecting women, men and children worldwide, but it is having a particularly devastating effect on the poorest and most marginalized in society. Emerging data show groups facing racial and ethnic discrimination are particularly affected. This includes people of African descent, indigenous peoples and other racial and ethnic minorities, and the women and girls among them. \\nIndigenous peoples have historically faced \\nmajor barriers to accessing medical careHundreds of indigenous women are without \\ntheir main source of income\\nEven before the pandemic, \\n77% \\nof indigenous households in the region of \\nGuajira, which straddles the border between \\nColombia and the Bolivarian Republic of \\nVenezuela, were food insecure and lacked the \\nmeans to lead a healthy and active life.Even before the \\npandemic, indigenous \\nwomen and girls were \\nless likely to have access \\nto health-care services,  \\nincluding maternal care, \\nthan those who are  \\nnon-indigenous.In Guatemala, the \\nmaternal mortality ratio \\nof indigenous women is  \\n3X \\nthat of non-indigenous \\nwomen.\\nWhen tourism \\nground to a halt, the \\nWayuu women of \\nAlta Guajira were \\nleft with no money or \\nfood to support their \\nfamilies. The Triqui women \\nfrom the highlands \\nof Oaxaca, Mexico, \\nwho rely on street \\nsales of handicrafts \\nand other products, \\nhave seen their \\nlivelihoods virtually \\ndisappear.COVID-19 IMPLICATIONSHEALTH ECONOMIC Women and girls from indigenous communities are especially vulnerableIN FOCUS\\nIn nearly all \\ncountries, indigenous \\npeoples have been \\ngrouped under the \\n‘most vulnerable to \\nCOVID-19’ health \\ncategory.Indigenous peoples \\nliving remotely \\nor in voluntary \\nisolation, who lack \\nimmunity to many \\ninfectious diseases, \\nare especially \\nthreatened. COVID-19 IMPLICATIONS', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='7bb41c78-f54d-40b4-b934-1e08fe23cf2a', embedding=None, metadata={'page_label': '6', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6\\nPROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS The pandemic is causing a resurgence in extreme poverty, affecting women the most\\nThe COVID-19 pandemic could reverse decades of progress in the eradication of poverty and inequality. Already, \\nwomen are more likely than men to live in extreme poverty. As the crisis exacerbates labour market instabilities along with gender inequalities in access to economic resources and in the division of unpaid care and domestic work, many more women are expected to fall into destitution. The total number of women and girls living on less than $1.90 a day is forecast to total 409 million in 2020 (up from 398.5 million in 2019), and peak at 435 million in 2021. That number is not expected to revert to pre-pandemic levels until 2030.\\nThe two main regions that will be affected most in terms of increased poverty will be sub-Saharan Africa and \\nSouthern Asia. In sub-Saharan Africa, between 2021 and 2030, the number of women and girls living in extremely poor households is expected to increase from 249 million to 283 million. By 2030, this region will be home to 71 per cent of women and girls living in extreme poverty. Central and Southern Asia, particularly the subregion of Southern Asia, has made major strides in reducing extreme poverty over the last several years. However, it will also see a resurgence in extreme poverty. Before the pandemic, projections suggested that, by 2030, Central and Southern Asia would comprise 15.8 per cent of the world’s women and girls living in extreme poverty. Revised projections now put that share at 18.6 per cent.\\nGlobal population living below the international poverty line, by sex, 2015-2030 projection \\n(millions)FIGURE 1\\nFemale (before COVID-19) Female (latest adjusted forecast) Male (before COVID-19) Male (latest adjusted forecast)\\nSource: UN Women, From Insights to Action: Gender Equality in the Wake of COVID-19, 2020.\\nNote: This analysis is based on a sample of 129 countries and areas accounting for 89 per cent of the global population. The latest adjusted forecasts for men and \\nwomen respectively are based on the International Monetary Fund’s June 2020 downward revision in global economic growth.\\n* The term ‘gender-specific indicators’ is used here and in subsequent sections of the Gender Snapshot to refer to indicators that explicitly call for disaggregation by \\nsex and/or refer to gender equality as an underlying objective. For a full list of gender-specific indicators by Goals, see pages 21-23 of this publication.GENDER-SPECIFIC INDICATORS*5 13 TO\\nINDICATAL  \\nTORS2015\\n2016\\n2017\\n2018\\n2019\\n2020\\n2021\\n2022\\n2023\\n2024\\n2025\\n2026\\n2027\\n203020292028450\\n425\\n400\\n375\\n350', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='d5ee5ce2-cf0e-4d5d-9583-04ab77ed4009', embedding=None, metadata={'page_label': '7', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='7\\nTHE GENDER SNAPSHOT 2020Severe levels of food insecurity are substantially higher for women than men, and \\nare likely to get worse \\nAt the global level, and more markedly in Northern Africa and Western Asia and in Latin America and the Caribbean, \\nthe gender gap in accessing sufficient food increased from 2018 to 2019, particularly at the moderate or severe levels. Women face more food insecurity than men, even when they have the same income and education levels. When various social and economic characteristics are controlled, statistical analyses reveal that the chances of being severely food insecure are about 27 per cent higher for women than for men at the global level. The bias is largest among individuals aged 25 to 49 years and among those who are separated or divorced. \\nThe number of people facing acute food insecurity in low- and middle-income countries will nearly double to \\n265 million by the end of 2020. Emerging data from humanitarian settings already point to increases in food insecurity, particularly among population groups whose nutritional needs are higher, such as pregnant and lactating women, women of reproductive age, adolescent girls, sick people, and those who are older.\\nSource: Global SDG Indicators Database, 2020. Note: Estimates cover persons aged 15 and older. Due to low coverage, estimates for Oceania (excluding Australia and \\nNew Zealand) are not shown. GENDER-SPECIFIC INDICATORS2 14 TO\\nINDICATAL  \\nTORS\\nProportion of the population who are moderately or severely food insecure, by sex, 2014-2019 (percentage)FIGURE 2\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019World\\n30\\n20\\n10\\n0Sub-Saharan Africa2014\\n2015\\n2016\\n2017\\n2018\\n201970\\n60\\n50\\n40\\n30\\n20\\n10\\n0\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019Eastern and South-Eastern Asia\\n20\\n10\\n0\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019Europe and Northern America\\n20\\n10\\n0\\nWomen (severe or moderate) Women (severe) Men (severe or moderate) Men (severe)\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019Latin America and the Caribbean\\n40\\n30\\n20\\n10\\n02014\\n2015\\n2016\\n2017\\n2018\\n2019Australia and New Zealand\\n20\\n10\\n0\\n2014\\n2015\\n2016\\n2017\\n2018\\n2019Central and Southern Asia\\n40\\n30\\n20\\n10\\n02014\\n2015\\n2016\\n2017\\n2018\\n2019Northern Africa and Western Asia\\n40\\n30\\n20\\n10\\n0', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='c3ed2bc0-7082-48a0-8ca7-f7fc1d107efd', embedding=None, metadata={'page_label': '8', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='8\\nPROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS Women health-care workers are on the front lines of the COVID-19 pandemic, putting \\ntheir lives at risk \\nThe pandemic is placing significant stress on health systems. Even the best-resourced systems in the most advanced \\ncountries have been strained to the breaking point at peak periods in the crisis. In addition, disruptions to routine health services are likely to limit women’s access to sexual and reproductive health care, including access to safe maternity care and modern contraception. Despite the ambitious goal to end preventable maternal deaths by 2030, at the current rate of progress the world is expected to fall short of the target by more than 1 million lives. Compounding the problem is the fact that more than 250 million women of reproductive age globally who want to prevent pregnancy are not using modern methods of contraception. \\nWomen represent 70 per cent of the world’s health-care workers. Thus, they are on the front lines of the pandemic and \\nat increased risk of exposure to the virus. Emerging data from the Dominican Republic, Germany, Ireland, Italy and Spain have confirmed that among infected health-care workers, 72 per cent are women. \\nConfirmed cases of COVID-19 among health-care workers, by sex, selected countries, \\nSeptember 2020 (number and percentage)FIGURE 3\\nSource: Compilation by Global Health 50/50 in 2020, using official national source for respective countries. In cases where data were not updated by Global Health 50/50, the latest health-care worker case data were updated using the latest bulletins from the official national source.GENDER-SPECIFIC INDICATORS6 28 TO\\nINDICATAL  \\nTORS\\nWomen Men40,957 \\nTotal health-care workers infected in Spain 31,351 | 77% 9,606 | 23%\\n30,927 \\nTotal health-care workers infected in Italy 21,649 | 70% 9,278 | 30%\\n13,941 \\nTotal health-care workers infected in Germany 10,177 | 73% 3,764 | 27%\\n388 \\nTotal health-care workers infected in the Dominican Republic 256 | 66% 132 | 34%8,691 \\nTotal health-care workers infected in Ireland 6,423  | 74% 2,268 | 26%', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='0b1f4285-ed3e-4fc2-b4c2-258ec5de46fb', embedding=None, metadata={'page_label': '9', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='9\\nTHE GENDER SNAPSHOT 2020School closures are likely to increase gender gaps in education and rates of child marriage\\nAt the height of the pandemic, 193 countries and areas temporarily closed educational institutions, affecting 1.7 billion \\nstudents. According to the latest reports from the UN Educational, Scientific and Cultural Organization (UNESCO), only one in three students will return to school this September, while the rest will continue to face school closures and uncertainty. Over 11 million girls – from pre-primary school to tertiary education age – may not return to school in 2020. \\nAlmost three quarters (73 per cent) of countries have begun implementing various forms of remote learning, including \\nonline classes. Yet not all children are benefiting equally. The poorest girls tend to suffer most since both their households and schools often lack computers and other related technologies. Among households that do have access to computers in the Democratic Republic of the Congo and in Ghana, girls have lower levels of computer skills than boys (17 and 18 per cent, respectively, for girls versus 56 and 49 per cent, respectively, for boys). Even before the pandemic, girls from the poorest households faced major obstacles to education: 44 per cent of girls compared to 34 per cent boys from the poorest families have never gone to school or dropped out before completing primary school. In Mali, Niger and South Sudan – which have some of the world’s lowest enrolment and completion rates for girls — closures have forced more than 4 million girls out of school. Similarly, refugee girls of secondary-school age are only half as likely to enrol in school as their male peers. Prolonged school closures may increase these gender gaps and lead to spikes in harmful practices such as child marriage, which further diminish girls’ chances of receiving an education. \\nSource: International Telecommunications Union (ITU), UN Children’s Fund (UNICEF), UNESCO Institute for Statistics, and UN Women, 2020.GENDER-SPECIFIC \\nINDICATORS8 12 TO\\nINDICATAL  \\nTORS\\nFIGURE 4\\nAT THE HEIGHT OF THE PANDEMIC, \\n1.7 billion\\nSTUDENTS\\nwere affected by school closures.\\nOver  \\n11 million  GIRLS\\nfrom pre-primary school to \\ntertiary education age are at risk of not returning to school in 2020.Girls from poor households are \\nmost likely to  \\nbe excluded. Remote learning measures  \\nare not reaching all learners. \\nOnly  \\n51% \\nof the world’s population are \\nconnected to the Internet.31%\\nOF COUNTRIES\\nprovided online-only alternatives to in-person schooling.27%\\nOF COUNTRIES\\nhad no remote learning \\nalternatives in place.\\nSEPTEMBER \\n2020 132 million \\nGIRLS AGED 6 TO 17\\nwere already out of school \\nbefore the pandemic.Only 1 in 3 \\nSTUDENTS \\nare expected to return to school. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='49169281-722a-4b59-827f-c1bd2625fdb2', embedding=None, metadata={'page_label': '10', 'file_name': 'GenderSnapshot_2020.pdf', 'file_path': '/tmp/GenderSnapshot_2020.pdf', 'file_type': 'application/pdf', 'file_size': 775381, 'creation_date': '2024-11-07', 'last_modified_date': '2024-11-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='10\\nPROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS Progress interrupted: COVID-19 could erase many of the hard-won \\ngains for the world’s women\\nThe year 2020 was supposed to be momentous – in a good way. World leaders and \\nwomen’s rights activists had planned to celebrate the anniversaries of key legal and policy instruments that are central to the realization of women’s human rights, including the 25th anniversary of the Beijing Declaration and Platform for Action and the 40th  anniversary of the Convention on the Elimination of All Forms of Discrimination against Women. However, the COVID-19 pandemic interrupted those plans and may reverse many of the hard-won gains of the past two decades. Women and girls are facing acute hardships, including higher rates of poverty, increased care burdens, greater exposure to violence and obstructed access to sexual and reproductive health services. And with few women directing policy responses at the national and local levels, such issues are not being sufficiently prioritized and resourced. Discriminatory laws and social norms also persist.\\nGlobally, an estimated \\n243  million \\nWOMEN AND GIRLS AGED 15 TO 49 \\nwere subjected to sexual and/or physical violence by an intimate partner in the previous year. COVID-19 and the resulting lockdown and confinement measures are widely presumed to have heightened women’s exposure to violence. \\nAt least \\n200 million \\nGIRLS AND WOMEN \\nhave been subjected to female genital mutilation, according to recent data from the 31 countries where this practice is concentrated.\\nFGM is becoming less common, but progress is not fast enough to meet the global target of eliminating it entirely by 2030. The prevalence of  \\nharmful practices,  \\nincluding child marriage and FGM, had been on a downward trajectory before the pandemic hit. Past experience, however, suggests that economic hardship and school disruptions could derail such progress.\\n10PROGRESS ON THE SUSTAINABLE DEVELOPMENT GOALS\\nIn 2019, \\n1 in 5 \\nWOMEN \\naged 20 to 24 years were married in childhood, down from one in four in 2004. ', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Requested entity was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1836177208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCS_BUCKET_NAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_doc_tools_for_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jt/f12_3w995dg5jn6dh4r5vvxm0000gn/T/ipykernel_37432/1812236866.py\u001b[0m in \u001b[0;36mget_doc_tools_for_bucket\u001b[0;34m(bucket_name, prefix)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes_from_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mvector_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorStoreIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0msummary_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             return cls(\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mstorage_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mindex_struct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex_struct\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 index_struct = self.build_index_from_nodes(\n\u001b[0m\u001b[1;32m     78\u001b[0m                     \u001b[0mnodes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36mbuild_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Some nodes are missing content, skipping them...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_index_from_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseNode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_build_index_from_nodes\u001b[0;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mrun_async_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             self._add_nodes_to_index(\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0mindex_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_add_nodes_to_index\u001b[0;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnodes_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mnodes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_with_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mnew_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vector_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minsert_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/vector_store/base.py\u001b[0m in \u001b[0;36m_get_node_with_embedding\u001b[0;34m(self, nodes, show_progress)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m         id_to_embed_map = embed_nodes(\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/indices/utils.py\u001b[0m in \u001b[0;36membed_nodes\u001b[0;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mid_to_embed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     new_embeddings = embed_model.get_text_embedding_batch(\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mtexts_to_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     )\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                     \u001b[0;31m# If the result is a Future, wrap it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/core/base/embeddings/base.py\u001b[0m in \u001b[0;36mget_text_embedding_batch\u001b[0;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mEventPayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERIALIZED\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 ) as event:\n\u001b[0;32m--> 335\u001b[0;31m                     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                     \u001b[0mresult_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                     event.on_end(\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/llama_index/embeddings/google/palm.py\u001b[0m in \u001b[0;36m_get_text_embeddings\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_text_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"\"\"Get text embeddings.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         return self._model.generate_embeddings(model=self.model_name, text=texts)[\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ]\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/generativeai/text.py\u001b[0m in \u001b[0;36mgenerate_embeddings\u001b[0;34m(model, text, client, request_options)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# TODO(markdaoust): This could use an option for returning an iterator or wait-bar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0membedding_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEmbedTextRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             embedding_response = client.batch_embed_text(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0membedding_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/text_service/client.py\u001b[0m in \u001b[0;36mbatch_embed_text\u001b[0;34m(self, request, model, texts, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 Requested entity was not found."
     ]
    }
   ],
   "source": [
    "bucket_name = GCS_BUCKET_NAME\n",
    "all_tools = get_doc_tools_for_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793ae38-e4c5-4441-b7ef-68ca42f2c1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jeaHR6EZEzZm",
   "metadata": {
    "id": "jeaHR6EZEzZm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ce88a-39e1-42a3-a231-feef0cea5dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Agentic_rag_using_vertex_ai2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
